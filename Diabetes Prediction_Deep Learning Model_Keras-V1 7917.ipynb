{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "Pregnancies                 768 non-null int64\n",
      "Glucose                     768 non-null int64\n",
      "BloodPressure               768 non-null int64\n",
      "SkinThickness               768 non-null int64\n",
      "Insulin                     768 non-null int64\n",
      "BMI                         768 non-null float64\n",
      "DiabetesPedigreeFunction    768 non-null float64\n",
      "Age                         768 non-null int64\n",
      "Outcome                     768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.info() \n",
    "diabetes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segregating categorical columns and numerical columns\n",
    "cat_columns = [col for col in diabetes.columns if diabetes[col].dtype in ['object']]\n",
    "numerical_columns = [col for col in diabetes.columns if diabetes[col].dtype in ['int32', 'float32', 'int64', 'float64']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns in dataset (no of columns - 0):  []\n",
      "Numerical columns in dataset (no of columns - 9) ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n"
     ]
    }
   ],
   "source": [
    "print('Categorical columns in dataset (no of columns - {}): '.format(len(cat_columns)), cat_columns)\n",
    "print('Numerical columns in dataset (no of columns - {})'.format(len(numerical_columns)),numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0.0\n",
       "Glucose                     0.0\n",
       "BloodPressure               0.0\n",
       "SkinThickness               0.0\n",
       "Insulin                     0.0\n",
       "BMI                         0.0\n",
       "DiabetesPedigreeFunction    0.0\n",
       "Age                         0.0\n",
       "Outcome                     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the percentage of missing values in each column\n",
    "diabetes.isnull().sum()/len(diabetes)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.groupby('Outcome')['Outcome'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ccff3e84e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Print the heatmap of correlations amongst the variables. This is possible as number of variables is less.\n",
    "plt.figure(figsize=(9,6))\n",
    "sns.heatmap(data=diabetes.corr(), cmap='viridis', annot=True, linecolor='w', linewidths=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  \n",
      "0                     0.627   50  \n",
      "1                     0.351   31  \n",
      "0    1\n",
      "1    0\n",
      "Name: Outcome, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#separate out the target variable\n",
    "data = diabetes.iloc[:,:-1]\n",
    "target = diabetes.iloc[:,-1]\n",
    "print(data.head(2))\n",
    "print(target.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling using Standard Scaler & MinMax Scaler. Any one to be commented out based on results\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#scaler = MinMaxScaler()\n",
    "#data_scaled = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((576, 8), (192, 8))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_scaled, target, test_size = 0.25, random_state = 1000)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=2,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=3,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_classifier = GradientBoostingClassifier(learning_rate=0.1, n_estimators=200, criterion = 'friedman_mse', \n",
    "                                           min_samples_split=3, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=2,)\n",
    "gb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = gb_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107  18]\n",
      " [ 26  41]]\n",
      "Accuracy Score:  0.7708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       125\n",
      "           1       0.69      0.61      0.65        67\n",
      "\n",
      "    accuracy                           0.77       192\n",
      "   macro avg       0.75      0.73      0.74       192\n",
      "weighted avg       0.77      0.77      0.77       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "print(confusion_matrix(y_test, y_hat))\n",
    "print('Accuracy Score: ', (accuracy_score(y_test, y_hat)).round(4))\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=GradientBoostingClassifier(criterion='friedman_mse',\n",
       "                                                  init=None, learning_rate=0.1,\n",
       "                                                  loss='deviance', max_depth=3,\n",
       "                                                  max_features=None,\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2,\n",
       "                                                  m...\n",
       "                                                  n_iter_no_change=None,\n",
       "                                                  presort='auto',\n",
       "                                                  random_state=None,\n",
       "                                                  subsample=1.0, tol=0.0001,\n",
       "                                                  validation_fraction=0.1,\n",
       "                                                  verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
       "                         'max_depth': [1, 2, 3, 4, 5, 6],\n",
       "                         'n_estimators': [100, 150, 200, 225, 250]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tuning Gradient Boosting Algorithm\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold\n",
    "\n",
    "n_estimators = [100,150,200,225,250];\n",
    "max_depth = [1,2,3,4,5,6];\n",
    "#criterions = ['friedman_mse'];\n",
    "#loss = ['deviance'];\n",
    "learning_rates = [0.01, 0.05, 0.1, 0.15, 0.2];\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "\n",
    "parameters = {'n_estimators':n_estimators,\n",
    "              'max_depth':max_depth,\n",
    "              'learning_rate':learning_rates\n",
    "             }\n",
    "\n",
    "gbc_grid = GridSearchCV(estimator=GradientBoostingClassifier(), param_grid=parameters, cv=cv, n_jobs= -1)\n",
    "gbc_grid.fit(data_scaled, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7721354166666666\n",
      "{'learning_rate': 0.15, 'max_depth': 1, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "print(gbc_grid.best_score_)\n",
    "print(gbc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=175,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(criterion='entropy',max_depth=8, max_features='auto', max_leaf_nodes=None, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=175)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111  14]\n",
      " [ 30  37]]\n",
      "Accuracy Score:  0.7708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.83       125\n",
      "           1       0.73      0.55      0.63        67\n",
      "\n",
      "    accuracy                           0.77       192\n",
      "   macro avg       0.76      0.72      0.73       192\n",
      "weighted avg       0.77      0.77      0.76       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_hat))\n",
    "print('Accuracy Score: ', (accuracy_score(y_test, y_hat)).round(4))\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep Learning Model with Keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split once more\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_scaled, target, test_size = 0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units=8, activation='relu', kernel_initializer = 'glorot_uniform', input_dim=8))\n",
    "    classifier.add(Dropout(0.3))\n",
    "    classifier.add(Dense(units=6, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "    classifier.add(Dropout(0.3))\n",
    "    classifier.add(Dense(units=6, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "    classifier.add(Dropout(0.2))\n",
    "    classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "    classifier.compile(optimizer=keras.optimizers.Adam(lr=0.004), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_classifier = build_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_77 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 175\n",
      "Trainable params: 175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "576/576 [==============================] - 1s 884us/step - loss: 0.7028 - accuracy: 0.5486\n",
      "Epoch 2/300\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.6406 - accuracy: 0.6250\n",
      "Epoch 3/300\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.6243 - accuracy: 0.66490s - loss: 0.6170 - accuracy: 0.67\n",
      "Epoch 4/300\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.5830 - accuracy: 0.6753\n",
      "Epoch 5/300\n",
      "576/576 [==============================] - 0s 155us/step - loss: 0.5960 - accuracy: 0.6771\n",
      "Epoch 6/300\n",
      "576/576 [==============================] - 0s 175us/step - loss: 0.5678 - accuracy: 0.6997\n",
      "Epoch 7/300\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.5851 - accuracy: 0.6840\n",
      "Epoch 8/300\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.5531 - accuracy: 0.7049\n",
      "Epoch 9/300\n",
      "576/576 [==============================] - 0s 210us/step - loss: 0.5648 - accuracy: 0.6997\n",
      "Epoch 10/300\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.5273 - accuracy: 0.7448\n",
      "Epoch 11/300\n",
      "576/576 [==============================] - 0s 180us/step - loss: 0.5181 - accuracy: 0.7465\n",
      "Epoch 12/300\n",
      "576/576 [==============================] - 0s 166us/step - loss: 0.5597 - accuracy: 0.7361\n",
      "Epoch 13/300\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.5320 - accuracy: 0.7274\n",
      "Epoch 14/300\n",
      "576/576 [==============================] - 0s 166us/step - loss: 0.5094 - accuracy: 0.7500\n",
      "Epoch 15/300\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.5217 - accuracy: 0.7483\n",
      "Epoch 16/300\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.5228 - accuracy: 0.7326\n",
      "Epoch 17/300\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.5023 - accuracy: 0.7465\n",
      "Epoch 18/300\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.4827 - accuracy: 0.7760\n",
      "Epoch 19/300\n",
      "576/576 [==============================] - 0s 185us/step - loss: 0.5018 - accuracy: 0.7726\n",
      "Epoch 20/300\n",
      "576/576 [==============================] - 0s 223us/step - loss: 0.5051 - accuracy: 0.7500\n",
      "Epoch 21/300\n",
      "576/576 [==============================] - 0s 234us/step - loss: 0.4934 - accuracy: 0.7465\n",
      "Epoch 22/300\n",
      "576/576 [==============================] - 0s 213us/step - loss: 0.5256 - accuracy: 0.7708\n",
      "Epoch 23/300\n",
      "576/576 [==============================] - 0s 220us/step - loss: 0.5233 - accuracy: 0.7396\n",
      "Epoch 24/300\n",
      "576/576 [==============================] - 0s 223us/step - loss: 0.4965 - accuracy: 0.7500\n",
      "Epoch 25/300\n",
      "576/576 [==============================] - 0s 223us/step - loss: 0.5323 - accuracy: 0.7361\n",
      "Epoch 26/300\n",
      "576/576 [==============================] - 0s 251us/step - loss: 0.5031 - accuracy: 0.7500\n",
      "Epoch 27/300\n",
      "576/576 [==============================] - 0s 241us/step - loss: 0.5080 - accuracy: 0.7535\n",
      "Epoch 28/300\n",
      "576/576 [==============================] - 0s 232us/step - loss: 0.4902 - accuracy: 0.7500\n",
      "Epoch 29/300\n",
      "576/576 [==============================] - 0s 248us/step - loss: 0.4820 - accuracy: 0.7413\n",
      "Epoch 30/300\n",
      "576/576 [==============================] - 0s 223us/step - loss: 0.5077 - accuracy: 0.7517\n",
      "Epoch 31/300\n",
      "576/576 [==============================] - 0s 229us/step - loss: 0.4942 - accuracy: 0.7622\n",
      "Epoch 32/300\n",
      "576/576 [==============================] - 0s 225us/step - loss: 0.4994 - accuracy: 0.7552\n",
      "Epoch 33/300\n",
      "576/576 [==============================] - 0s 241us/step - loss: 0.4980 - accuracy: 0.7587\n",
      "Epoch 34/300\n",
      "576/576 [==============================] - 0s 241us/step - loss: 0.4937 - accuracy: 0.7708\n",
      "Epoch 35/300\n",
      "576/576 [==============================] - 0s 230us/step - loss: 0.5063 - accuracy: 0.7569\n",
      "Epoch 36/300\n",
      "576/576 [==============================] - 0s 225us/step - loss: 0.5037 - accuracy: 0.7587\n",
      "Epoch 37/300\n",
      "576/576 [==============================] - 0s 218us/step - loss: 0.4887 - accuracy: 0.7622\n",
      "Epoch 38/300\n",
      "576/576 [==============================] - 0s 204us/step - loss: 0.5110 - accuracy: 0.7535\n",
      "Epoch 39/300\n",
      "576/576 [==============================] - 0s 194us/step - loss: 0.4930 - accuracy: 0.7656\n",
      "Epoch 40/300\n",
      "576/576 [==============================] - 0s 220us/step - loss: 0.4870 - accuracy: 0.7656\n",
      "Epoch 41/300\n",
      "576/576 [==============================] - 0s 182us/step - loss: 0.4861 - accuracy: 0.7708\n",
      "Epoch 42/300\n",
      "576/576 [==============================] - 0s 178us/step - loss: 0.5027 - accuracy: 0.7604\n",
      "Epoch 43/300\n",
      "576/576 [==============================] - 0s 178us/step - loss: 0.4968 - accuracy: 0.7552\n",
      "Epoch 44/300\n",
      "576/576 [==============================] - 0s 244us/step - loss: 0.5080 - accuracy: 0.7465\n",
      "Epoch 45/300\n",
      "576/576 [==============================] - 0s 234us/step - loss: 0.4935 - accuracy: 0.7639\n",
      "Epoch 46/300\n",
      "576/576 [==============================] - 0s 215us/step - loss: 0.4941 - accuracy: 0.7691\n",
      "Epoch 47/300\n",
      "576/576 [==============================] - 0s 210us/step - loss: 0.5089 - accuracy: 0.7344\n",
      "Epoch 48/300\n",
      "576/576 [==============================] - 0s 173us/step - loss: 0.4783 - accuracy: 0.7604\n",
      "Epoch 49/300\n",
      "576/576 [==============================] - 0s 199us/step - loss: 0.4903 - accuracy: 0.7535\n",
      "Epoch 50/300\n",
      "576/576 [==============================] - 0s 192us/step - loss: 0.4914 - accuracy: 0.7604\n",
      "Epoch 51/300\n",
      "576/576 [==============================] - 0s 208us/step - loss: 0.4746 - accuracy: 0.7656\n",
      "Epoch 52/300\n",
      "576/576 [==============================] - 0s 203us/step - loss: 0.4989 - accuracy: 0.7361\n",
      "Epoch 53/300\n",
      "576/576 [==============================] - 0s 211us/step - loss: 0.4811 - accuracy: 0.7604\n",
      "Epoch 54/300\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.4955 - accuracy: 0.7604\n",
      "Epoch 55/300\n",
      "576/576 [==============================] - 0s 218us/step - loss: 0.4968 - accuracy: 0.7448\n",
      "Epoch 56/300\n",
      "576/576 [==============================] - 0s 210us/step - loss: 0.4860 - accuracy: 0.7708\n",
      "Epoch 57/300\n",
      "576/576 [==============================] - 0s 197us/step - loss: 0.4860 - accuracy: 0.7639\n",
      "Epoch 58/300\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.4760 - accuracy: 0.7691\n",
      "Epoch 59/300\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4819 - accuracy: 0.7691\n",
      "Epoch 60/300\n",
      "576/576 [==============================] - 0s 177us/step - loss: 0.4779 - accuracy: 0.7604\n",
      "Epoch 61/300\n",
      "576/576 [==============================] - 0s 206us/step - loss: 0.4760 - accuracy: 0.7604\n",
      "Epoch 62/300\n",
      "576/576 [==============================] - 0s 184us/step - loss: 0.4722 - accuracy: 0.7569\n",
      "Epoch 63/300\n",
      "576/576 [==============================] - 0s 204us/step - loss: 0.4824 - accuracy: 0.7587\n",
      "Epoch 64/300\n",
      "576/576 [==============================] - 0s 184us/step - loss: 0.4798 - accuracy: 0.7344\n",
      "Epoch 65/300\n",
      "576/576 [==============================] - 0s 177us/step - loss: 0.4963 - accuracy: 0.7431\n",
      "Epoch 66/300\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.4842 - accuracy: 0.7778\n",
      "Epoch 67/300\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.4794 - accuracy: 0.7691\n",
      "Epoch 68/300\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4712 - accuracy: 0.7674\n",
      "Epoch 69/300\n",
      "576/576 [==============================] - 0s 180us/step - loss: 0.4981 - accuracy: 0.7431\n",
      "Epoch 70/300\n",
      "576/576 [==============================] - 0s 196us/step - loss: 0.4746 - accuracy: 0.7656\n",
      "Epoch 71/300\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.4999 - accuracy: 0.7465\n",
      "Epoch 72/300\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4624 - accuracy: 0.7656\n",
      "Epoch 73/300\n",
      "576/576 [==============================] - 0s 210us/step - loss: 0.4704 - accuracy: 0.7760\n",
      "Epoch 74/300\n",
      "576/576 [==============================] - 0s 230us/step - loss: 0.4823 - accuracy: 0.7708\n",
      "Epoch 75/300\n",
      "576/576 [==============================] - 0s 222us/step - loss: 0.4580 - accuracy: 0.7726\n",
      "Epoch 76/300\n",
      "576/576 [==============================] - 0s 184us/step - loss: 0.4779 - accuracy: 0.7465\n",
      "Epoch 77/300\n",
      "576/576 [==============================] - 0s 199us/step - loss: 0.4729 - accuracy: 0.7639\n",
      "Epoch 78/300\n",
      "576/576 [==============================] - 0s 210us/step - loss: 0.4653 - accuracy: 0.7622\n",
      "Epoch 79/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 196us/step - loss: 0.4868 - accuracy: 0.7604\n",
      "Epoch 80/300\n",
      "576/576 [==============================] - 0s 178us/step - loss: 0.4642 - accuracy: 0.7726\n",
      "Epoch 81/300\n",
      "576/576 [==============================] - 0s 201us/step - loss: 0.4855 - accuracy: 0.7708\n",
      "Epoch 82/300\n",
      "576/576 [==============================] - 0s 196us/step - loss: 0.4760 - accuracy: 0.7691\n",
      "Epoch 83/300\n",
      "576/576 [==============================] - 0s 197us/step - loss: 0.4819 - accuracy: 0.7465\n",
      "Epoch 84/300\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4886 - accuracy: 0.7622\n",
      "Epoch 85/300\n",
      "576/576 [==============================] - 0s 154us/step - loss: 0.4662 - accuracy: 0.7639\n",
      "Epoch 86/300\n",
      "576/576 [==============================] - 0s 166us/step - loss: 0.5006 - accuracy: 0.7413\n",
      "Epoch 87/300\n",
      "576/576 [==============================] - 0s 154us/step - loss: 0.4869 - accuracy: 0.7604\n",
      "Epoch 88/300\n",
      "576/576 [==============================] - 0s 201us/step - loss: 0.4867 - accuracy: 0.7795\n",
      "Epoch 89/300\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4675 - accuracy: 0.7830\n",
      "Epoch 90/300\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.4687 - accuracy: 0.7656\n",
      "Epoch 91/300\n",
      "576/576 [==============================] - 0s 156us/step - loss: 0.4768 - accuracy: 0.7500\n",
      "Epoch 92/300\n",
      "576/576 [==============================] - 0s 246us/step - loss: 0.4833 - accuracy: 0.7708\n",
      "Epoch 93/300\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.4767 - accuracy: 0.7448\n",
      "Epoch 94/300\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.4597 - accuracy: 0.7726\n",
      "Epoch 95/300\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4730 - accuracy: 0.7656\n",
      "Epoch 96/300\n",
      "576/576 [==============================] - 0s 152us/step - loss: 0.4784 - accuracy: 0.7656\n",
      "Epoch 97/300\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.4731 - accuracy: 0.7639\n",
      "Epoch 98/300\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.4631 - accuracy: 0.7882\n",
      "Epoch 99/300\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.4478 - accuracy: 0.7708\n",
      "Epoch 100/300\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4800 - accuracy: 0.7483\n",
      "Epoch 101/300\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4687 - accuracy: 0.7569\n",
      "Epoch 102/300\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.4585 - accuracy: 0.7760\n",
      "Epoch 103/300\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4776 - accuracy: 0.7778\n",
      "Epoch 104/300\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.4794 - accuracy: 0.7622\n",
      "Epoch 105/300\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4815 - accuracy: 0.7587\n",
      "Epoch 106/300\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4906 - accuracy: 0.7569\n",
      "Epoch 107/300\n",
      "576/576 [==============================] - 0s 187us/step - loss: 0.4599 - accuracy: 0.7708\n",
      "Epoch 108/300\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4585 - accuracy: 0.7691\n",
      "Epoch 109/300\n",
      "576/576 [==============================] - 0s 156us/step - loss: 0.4706 - accuracy: 0.7674\n",
      "Epoch 110/300\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4704 - accuracy: 0.76740s - loss: 0.4680 - accuracy: 0.77\n",
      "Epoch 111/300\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4616 - accuracy: 0.7760\n",
      "Epoch 112/300\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4823 - accuracy: 0.7535\n",
      "Epoch 113/300\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4667 - accuracy: 0.7917\n",
      "Epoch 114/300\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4579 - accuracy: 0.7743\n",
      "Epoch 115/300\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4867 - accuracy: 0.7326\n",
      "Epoch 116/300\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4776 - accuracy: 0.7483\n",
      "Epoch 117/300\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4684 - accuracy: 0.7674\n",
      "Epoch 118/300\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4915 - accuracy: 0.7309\n",
      "Epoch 119/300\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4828 - accuracy: 0.7622\n",
      "Epoch 120/300\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4728 - accuracy: 0.7535\n",
      "Epoch 121/300\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4628 - accuracy: 0.7674\n",
      "Epoch 122/300\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4535 - accuracy: 0.7760\n",
      "Epoch 123/300\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4640 - accuracy: 0.7760\n",
      "Epoch 124/300\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4545 - accuracy: 0.7760\n",
      "Epoch 125/300\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4707 - accuracy: 0.7622\n",
      "Epoch 126/300\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4575 - accuracy: 0.7847\n",
      "Epoch 127/300\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4679 - accuracy: 0.7760\n",
      "Epoch 128/300\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.4761 - accuracy: 0.7500\n",
      "Epoch 129/300\n",
      "576/576 [==============================] - 0s 175us/step - loss: 0.4670 - accuracy: 0.7587\n",
      "Epoch 130/300\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4855 - accuracy: 0.7483\n",
      "Epoch 131/300\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4367 - accuracy: 0.7986\n",
      "Epoch 132/300\n",
      "576/576 [==============================] - 0s 173us/step - loss: 0.4624 - accuracy: 0.7743\n",
      "Epoch 133/300\n",
      "576/576 [==============================] - 0s 184us/step - loss: 0.4706 - accuracy: 0.7795\n",
      "Epoch 134/300\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.4500 - accuracy: 0.7726\n",
      "Epoch 135/300\n",
      "576/576 [==============================] - 0s 190us/step - loss: 0.4650 - accuracy: 0.7691\n",
      "Epoch 136/300\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.4518 - accuracy: 0.7604\n",
      "Epoch 137/300\n",
      "576/576 [==============================] - 0s 187us/step - loss: 0.4661 - accuracy: 0.7760\n",
      "Epoch 138/300\n",
      "576/576 [==============================] - 0s 190us/step - loss: 0.4519 - accuracy: 0.7847\n",
      "Epoch 139/300\n",
      "576/576 [==============================] - 0s 175us/step - loss: 0.4780 - accuracy: 0.7587\n",
      "Epoch 140/300\n",
      "576/576 [==============================] - 0s 180us/step - loss: 0.4611 - accuracy: 0.7795\n",
      "Epoch 141/300\n",
      "576/576 [==============================] - 0s 175us/step - loss: 0.4747 - accuracy: 0.7708\n",
      "Epoch 142/300\n",
      "576/576 [==============================] - 0s 177us/step - loss: 0.4959 - accuracy: 0.7465\n",
      "Epoch 143/300\n",
      "576/576 [==============================] - 0s 166us/step - loss: 0.4635 - accuracy: 0.7726\n",
      "Epoch 144/300\n",
      "576/576 [==============================] - 0s 190us/step - loss: 0.4535 - accuracy: 0.7830\n",
      "Epoch 145/300\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4477 - accuracy: 0.7899\n",
      "Epoch 146/300\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4706 - accuracy: 0.7587\n",
      "Epoch 147/300\n",
      "576/576 [==============================] - 0s 182us/step - loss: 0.4620 - accuracy: 0.7500\n",
      "Epoch 148/300\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.4528 - accuracy: 0.7951\n",
      "Epoch 149/300\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.4582 - accuracy: 0.7639\n",
      "Epoch 150/300\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.4562 - accuracy: 0.7587\n",
      "Epoch 151/300\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.4523 - accuracy: 0.7812\n",
      "Epoch 152/300\n",
      "576/576 [==============================] - 0s 173us/step - loss: 0.4617 - accuracy: 0.7830\n",
      "Epoch 153/300\n",
      "576/576 [==============================] - 0s 173us/step - loss: 0.4772 - accuracy: 0.7622\n",
      "Epoch 154/300\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.4645 - accuracy: 0.7622\n",
      "Epoch 155/300\n",
      "576/576 [==============================] - 0s 201us/step - loss: 0.4608 - accuracy: 0.7639\n",
      "Epoch 156/300\n",
      "576/576 [==============================] - 0s 251us/step - loss: 0.4640 - accuracy: 0.7691\n",
      "Epoch 157/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 197us/step - loss: 0.4642 - accuracy: 0.7569\n",
      "Epoch 158/300\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4789 - accuracy: 0.7656\n",
      "Epoch 159/300\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4297 - accuracy: 0.7778\n",
      "Epoch 160/300\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.4671 - accuracy: 0.7830\n",
      "Epoch 161/300\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4638 - accuracy: 0.7552\n",
      "Epoch 162/300\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.4535 - accuracy: 0.7656\n",
      "Epoch 163/300\n",
      "576/576 [==============================] - 0s 225us/step - loss: 0.4527 - accuracy: 0.7882\n",
      "Epoch 164/300\n",
      "576/576 [==============================] - 0s 239us/step - loss: 0.4703 - accuracy: 0.7708\n",
      "Epoch 165/300\n",
      "576/576 [==============================] - 0s 204us/step - loss: 0.4752 - accuracy: 0.7413\n",
      "Epoch 166/300\n",
      "576/576 [==============================] - 0s 173us/step - loss: 0.4690 - accuracy: 0.7760\n",
      "Epoch 167/300\n",
      "576/576 [==============================] - 0s 180us/step - loss: 0.4514 - accuracy: 0.7726\n",
      "Epoch 168/300\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4711 - accuracy: 0.7708\n",
      "Epoch 169/300\n",
      "576/576 [==============================] - 0s 182us/step - loss: 0.4774 - accuracy: 0.7569\n",
      "Epoch 170/300\n",
      "576/576 [==============================] - 0s 246us/step - loss: 0.4635 - accuracy: 0.7656\n",
      "Epoch 171/300\n",
      "576/576 [==============================] - 0s 220us/step - loss: 0.4705 - accuracy: 0.7639\n",
      "Epoch 172/300\n",
      "576/576 [==============================] - 0s 222us/step - loss: 0.4751 - accuracy: 0.7500\n",
      "Epoch 173/300\n",
      "576/576 [==============================] - 0s 229us/step - loss: 0.4532 - accuracy: 0.7917\n",
      "Epoch 174/300\n",
      "576/576 [==============================] - 0s 218us/step - loss: 0.4789 - accuracy: 0.7674\n",
      "Epoch 175/300\n",
      "576/576 [==============================] - 0s 206us/step - loss: 0.4932 - accuracy: 0.7309\n",
      "Epoch 176/300\n",
      "576/576 [==============================] - 0s 204us/step - loss: 0.4657 - accuracy: 0.7656\n",
      "Epoch 177/300\n",
      "576/576 [==============================] - 0s 206us/step - loss: 0.4567 - accuracy: 0.7795\n",
      "Epoch 178/300\n",
      "576/576 [==============================] - 0s 260us/step - loss: 0.4589 - accuracy: 0.7812\n",
      "Epoch 179/300\n",
      "576/576 [==============================] - 0s 232us/step - loss: 0.4654 - accuracy: 0.7535\n",
      "Epoch 180/300\n",
      "576/576 [==============================] - 0s 227us/step - loss: 0.4606 - accuracy: 0.7691\n",
      "Epoch 181/300\n",
      "576/576 [==============================] - 0s 225us/step - loss: 0.4673 - accuracy: 0.7726\n",
      "Epoch 182/300\n",
      "576/576 [==============================] - 0s 235us/step - loss: 0.4817 - accuracy: 0.7552\n",
      "Epoch 183/300\n",
      "576/576 [==============================] - 0s 215us/step - loss: 0.4770 - accuracy: 0.7465\n",
      "Epoch 184/300\n",
      "576/576 [==============================] - 0s 208us/step - loss: 0.4711 - accuracy: 0.7986\n",
      "Epoch 185/300\n",
      "576/576 [==============================] - 0s 210us/step - loss: 0.4786 - accuracy: 0.7552\n",
      "Epoch 186/300\n",
      "576/576 [==============================] - 0s 253us/step - loss: 0.4434 - accuracy: 0.7969\n",
      "Epoch 187/300\n",
      "576/576 [==============================] - 0s 225us/step - loss: 0.4731 - accuracy: 0.7587\n",
      "Epoch 188/300\n",
      "576/576 [==============================] - 0s 246us/step - loss: 0.4351 - accuracy: 0.8021\n",
      "Epoch 189/300\n",
      "576/576 [==============================] - 0s 227us/step - loss: 0.4427 - accuracy: 0.7622\n",
      "Epoch 190/300\n",
      "576/576 [==============================] - 0s 227us/step - loss: 0.4602 - accuracy: 0.7691\n",
      "Epoch 191/300\n",
      "576/576 [==============================] - 0s 241us/step - loss: 0.4601 - accuracy: 0.7778\n",
      "Epoch 192/300\n",
      "576/576 [==============================] - 0s 182us/step - loss: 0.4601 - accuracy: 0.7674\n",
      "Epoch 193/300\n",
      "576/576 [==============================] - 0s 210us/step - loss: 0.4935 - accuracy: 0.7622\n",
      "Epoch 194/300\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.4583 - accuracy: 0.7517\n",
      "Epoch 195/300\n",
      "576/576 [==============================] - 0s 187us/step - loss: 0.4543 - accuracy: 0.7674\n",
      "Epoch 196/300\n",
      "576/576 [==============================] - 0s 190us/step - loss: 0.4563 - accuracy: 0.7847\n",
      "Epoch 197/300\n",
      "576/576 [==============================] - 0s 173us/step - loss: 0.4709 - accuracy: 0.7674\n",
      "Epoch 198/300\n",
      "576/576 [==============================] - 0s 166us/step - loss: 0.4524 - accuracy: 0.7865\n",
      "Epoch 199/300\n",
      "576/576 [==============================] - 0s 175us/step - loss: 0.4416 - accuracy: 0.7917\n",
      "Epoch 200/300\n",
      "576/576 [==============================] - 0s 177us/step - loss: 0.4679 - accuracy: 0.7691\n",
      "Epoch 201/300\n",
      "576/576 [==============================] - 0s 196us/step - loss: 0.4571 - accuracy: 0.7552\n",
      "Epoch 202/300\n",
      "576/576 [==============================] - 0s 196us/step - loss: 0.4769 - accuracy: 0.7552\n",
      "Epoch 203/300\n",
      "576/576 [==============================] - 0s 201us/step - loss: 0.4536 - accuracy: 0.7708\n",
      "Epoch 204/300\n",
      "576/576 [==============================] - 0s 201us/step - loss: 0.4664 - accuracy: 0.7830\n",
      "Epoch 205/300\n",
      "576/576 [==============================] - 0s 173us/step - loss: 0.4412 - accuracy: 0.7917\n",
      "Epoch 206/300\n",
      "576/576 [==============================] - 0s 208us/step - loss: 0.4647 - accuracy: 0.7865\n",
      "Epoch 207/300\n",
      "576/576 [==============================] - 0s 211us/step - loss: 0.4512 - accuracy: 0.7726\n",
      "Epoch 208/300\n",
      "576/576 [==============================] - 0s 197us/step - loss: 0.4590 - accuracy: 0.7708\n",
      "Epoch 209/300\n",
      "576/576 [==============================] - 0s 177us/step - loss: 0.4418 - accuracy: 0.7830\n",
      "Epoch 210/300\n",
      "576/576 [==============================] - 0s 196us/step - loss: 0.4744 - accuracy: 0.7708\n",
      "Epoch 211/300\n",
      "576/576 [==============================] - 0s 204us/step - loss: 0.4693 - accuracy: 0.7639\n",
      "Epoch 212/300\n",
      "576/576 [==============================] - 0s 184us/step - loss: 0.4544 - accuracy: 0.7760\n",
      "Epoch 213/300\n",
      "576/576 [==============================] - 0s 229us/step - loss: 0.4665 - accuracy: 0.7674\n",
      "Epoch 214/300\n",
      "576/576 [==============================] - 0s 204us/step - loss: 0.4636 - accuracy: 0.7535\n",
      "Epoch 215/300\n",
      "576/576 [==============================] - 0s 185us/step - loss: 0.4588 - accuracy: 0.7639\n",
      "Epoch 216/300\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4524 - accuracy: 0.7760\n",
      "Epoch 217/300\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.4461 - accuracy: 0.8021\n",
      "Epoch 218/300\n",
      "576/576 [==============================] - 0s 218us/step - loss: 0.4643 - accuracy: 0.7726\n",
      "Epoch 219/300\n",
      "576/576 [==============================] - 0s 211us/step - loss: 0.4631 - accuracy: 0.7865\n",
      "Epoch 220/300\n",
      "576/576 [==============================] - 0s 211us/step - loss: 0.4793 - accuracy: 0.7656\n",
      "Epoch 221/300\n",
      "576/576 [==============================] - 0s 210us/step - loss: 0.4508 - accuracy: 0.8003\n",
      "Epoch 222/300\n",
      "576/576 [==============================] - 0s 185us/step - loss: 0.4761 - accuracy: 0.7622\n",
      "Epoch 223/300\n",
      "576/576 [==============================] - 0s 194us/step - loss: 0.4906 - accuracy: 0.7587\n",
      "Epoch 224/300\n",
      "576/576 [==============================] - 0s 185us/step - loss: 0.4641 - accuracy: 0.7639\n",
      "Epoch 225/300\n",
      "576/576 [==============================] - 0s 173us/step - loss: 0.4637 - accuracy: 0.7656\n",
      "Epoch 226/300\n",
      "576/576 [==============================] - 0s 173us/step - loss: 0.4690 - accuracy: 0.7865\n",
      "Epoch 227/300\n",
      "576/576 [==============================] - 0s 194us/step - loss: 0.4676 - accuracy: 0.7743\n",
      "Epoch 228/300\n",
      "576/576 [==============================] - 0s 213us/step - loss: 0.4712 - accuracy: 0.7691\n",
      "Epoch 229/300\n",
      "576/576 [==============================] - 0s 184us/step - loss: 0.4555 - accuracy: 0.7639\n",
      "Epoch 230/300\n",
      "576/576 [==============================] - 0s 180us/step - loss: 0.4749 - accuracy: 0.7569\n",
      "Epoch 231/300\n",
      "576/576 [==============================] - 0s 206us/step - loss: 0.4685 - accuracy: 0.7622\n",
      "Epoch 232/300\n",
      "576/576 [==============================] - 0s 232us/step - loss: 0.4562 - accuracy: 0.7483\n",
      "Epoch 233/300\n",
      "576/576 [==============================] - 0s 201us/step - loss: 0.4601 - accuracy: 0.7656\n",
      "Epoch 234/300\n",
      "576/576 [==============================] - 0s 175us/step - loss: 0.4721 - accuracy: 0.7674\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 171us/step - loss: 0.4575 - accuracy: 0.7587\n",
      "Epoch 236/300\n",
      "576/576 [==============================] - 0s 206us/step - loss: 0.4670 - accuracy: 0.7726\n",
      "Epoch 237/300\n",
      "576/576 [==============================] - 0s 182us/step - loss: 0.4437 - accuracy: 0.7708\n",
      "Epoch 238/300\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4582 - accuracy: 0.7726\n",
      "Epoch 239/300\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.4681 - accuracy: 0.7691\n",
      "Epoch 240/300\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4373 - accuracy: 0.7882\n",
      "Epoch 241/300\n",
      "576/576 [==============================] - 0s 175us/step - loss: 0.4545 - accuracy: 0.7500\n",
      "Epoch 242/300\n",
      "576/576 [==============================] - 0s 204us/step - loss: 0.4656 - accuracy: 0.7726\n",
      "Epoch 243/300\n",
      "576/576 [==============================] - 0s 180us/step - loss: 0.4642 - accuracy: 0.7865\n",
      "Epoch 244/300\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4620 - accuracy: 0.7639\n",
      "Epoch 245/300\n",
      "576/576 [==============================] - 0s 203us/step - loss: 0.4688 - accuracy: 0.7639\n",
      "Epoch 246/300\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4621 - accuracy: 0.7656\n",
      "Epoch 247/300\n",
      "576/576 [==============================] - 0s 175us/step - loss: 0.4619 - accuracy: 0.7830\n",
      "Epoch 248/300\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4553 - accuracy: 0.7917\n",
      "Epoch 249/300\n",
      "576/576 [==============================] - 0s 175us/step - loss: 0.4755 - accuracy: 0.7604\n",
      "Epoch 250/300\n",
      "576/576 [==============================] - 0s 199us/step - loss: 0.4627 - accuracy: 0.7795\n",
      "Epoch 251/300\n",
      "576/576 [==============================] - 0s 173us/step - loss: 0.4773 - accuracy: 0.7604\n",
      "Epoch 252/300\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.4520 - accuracy: 0.7778\n",
      "Epoch 253/300\n",
      "576/576 [==============================] - 0s 166us/step - loss: 0.4599 - accuracy: 0.7795\n",
      "Epoch 254/300\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.4529 - accuracy: 0.7795\n",
      "Epoch 255/300\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4481 - accuracy: 0.7639\n",
      "Epoch 256/300\n",
      "576/576 [==============================] - 0s 208us/step - loss: 0.4638 - accuracy: 0.7726\n",
      "Epoch 257/300\n",
      "576/576 [==============================] - 0s 187us/step - loss: 0.4359 - accuracy: 0.8003\n",
      "Epoch 258/300\n",
      "576/576 [==============================] - 0s 173us/step - loss: 0.4798 - accuracy: 0.7674\n",
      "Epoch 259/300\n",
      "576/576 [==============================] - 0s 210us/step - loss: 0.4682 - accuracy: 0.7535\n",
      "Epoch 260/300\n",
      "576/576 [==============================] - 0s 197us/step - loss: 0.4515 - accuracy: 0.7830\n",
      "Epoch 261/300\n",
      "576/576 [==============================] - 0s 194us/step - loss: 0.4580 - accuracy: 0.7639\n",
      "Epoch 262/300\n",
      "576/576 [==============================] - 0s 244us/step - loss: 0.4864 - accuracy: 0.7500\n",
      "Epoch 263/300\n",
      "576/576 [==============================] - 0s 261us/step - loss: 0.4655 - accuracy: 0.7569\n",
      "Epoch 264/300\n",
      "576/576 [==============================] - 0s 194us/step - loss: 0.4651 - accuracy: 0.7500\n",
      "Epoch 265/300\n",
      "576/576 [==============================] - 0s 173us/step - loss: 0.4679 - accuracy: 0.7830\n",
      "Epoch 266/300\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4410 - accuracy: 0.7882\n",
      "Epoch 267/300\n",
      "576/576 [==============================] - 0s 182us/step - loss: 0.4519 - accuracy: 0.7847\n",
      "Epoch 268/300\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.4505 - accuracy: 0.7639\n",
      "Epoch 269/300\n",
      "576/576 [==============================] - 0s 206us/step - loss: 0.4486 - accuracy: 0.7847\n",
      "Epoch 270/300\n",
      "576/576 [==============================] - 0s 213us/step - loss: 0.4839 - accuracy: 0.7622\n",
      "Epoch 271/300\n",
      "576/576 [==============================] - 0s 208us/step - loss: 0.4543 - accuracy: 0.7569\n",
      "Epoch 272/300\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4664 - accuracy: 0.7483\n",
      "Epoch 273/300\n",
      "576/576 [==============================] - 0s 166us/step - loss: 0.4692 - accuracy: 0.7622\n",
      "Epoch 274/300\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.4456 - accuracy: 0.8003\n",
      "Epoch 275/300\n",
      "576/576 [==============================] - 0s 185us/step - loss: 0.4516 - accuracy: 0.7899\n",
      "Epoch 276/300\n",
      "576/576 [==============================] - 0s 184us/step - loss: 0.4526 - accuracy: 0.7569\n",
      "Epoch 277/300\n",
      "576/576 [==============================] - 0s 234us/step - loss: 0.4469 - accuracy: 0.7760\n",
      "Epoch 278/300\n",
      "576/576 [==============================] - 0s 235us/step - loss: 0.4538 - accuracy: 0.7795\n",
      "Epoch 279/300\n",
      "576/576 [==============================] - 0s 201us/step - loss: 0.4431 - accuracy: 0.7899\n",
      "Epoch 280/300\n",
      "576/576 [==============================] - 0s 248us/step - loss: 0.4647 - accuracy: 0.7760\n",
      "Epoch 281/300\n",
      "576/576 [==============================] - 0s 222us/step - loss: 0.4628 - accuracy: 0.7743\n",
      "Epoch 282/300\n",
      "576/576 [==============================] - 0s 218us/step - loss: 0.4725 - accuracy: 0.7708\n",
      "Epoch 283/300\n",
      "576/576 [==============================] - 0s 270us/step - loss: 0.4634 - accuracy: 0.7830\n",
      "Epoch 284/300\n",
      "576/576 [==============================] - 0s 213us/step - loss: 0.4447 - accuracy: 0.7830\n",
      "Epoch 285/300\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4575 - accuracy: 0.79 - 0s 185us/step - loss: 0.4802 - accuracy: 0.7708\n",
      "Epoch 286/300\n",
      "576/576 [==============================] - 0s 178us/step - loss: 0.4518 - accuracy: 0.7622\n",
      "Epoch 287/300\n",
      "576/576 [==============================] - 0s 175us/step - loss: 0.4622 - accuracy: 0.7587\n",
      "Epoch 288/300\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.4638 - accuracy: 0.7517\n",
      "Epoch 289/300\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4611 - accuracy: 0.7622\n",
      "Epoch 290/300\n",
      "576/576 [==============================] - 0s 177us/step - loss: 0.4550 - accuracy: 0.7569\n",
      "Epoch 291/300\n",
      "576/576 [==============================] - 0s 185us/step - loss: 0.4593 - accuracy: 0.7760\n",
      "Epoch 292/300\n",
      "576/576 [==============================] - 0s 197us/step - loss: 0.4651 - accuracy: 0.7569\n",
      "Epoch 293/300\n",
      "576/576 [==============================] - 0s 178us/step - loss: 0.4481 - accuracy: 0.7691\n",
      "Epoch 294/300\n",
      "576/576 [==============================] - 0s 204us/step - loss: 0.4656 - accuracy: 0.7708\n",
      "Epoch 295/300\n",
      "576/576 [==============================] - 0s 182us/step - loss: 0.4579 - accuracy: 0.7587\n",
      "Epoch 296/300\n",
      "576/576 [==============================] - 0s 216us/step - loss: 0.4567 - accuracy: 0.7743\n",
      "Epoch 297/300\n",
      "576/576 [==============================] - 0s 216us/step - loss: 0.4613 - accuracy: 0.7778\n",
      "Epoch 298/300\n",
      "576/576 [==============================] - 0s 232us/step - loss: 0.4763 - accuracy: 0.7587\n",
      "Epoch 299/300\n",
      "576/576 [==============================] - 0s 218us/step - loss: 0.4451 - accuracy: 0.7865\n",
      "Epoch 300/300\n",
      "576/576 [==============================] - 0s 230us/step - loss: 0.4418 - accuracy: 0.7743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1cca4616cc0>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_classifier.fit(X_train, y_train, batch_size=16, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = nn_classifier.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_hat[y_hat > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98 27]\n",
      " [13 54]]\n",
      "Accuracy Score:  0.7917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.83       125\n",
      "           1       0.67      0.81      0.73        67\n",
      "\n",
      "    accuracy                           0.79       192\n",
      "   macro avg       0.77      0.79      0.78       192\n",
      "weighted avg       0.81      0.79      0.80       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_hat))\n",
    "print('Accuracy Score: ', (accuracy_score(y_test, y_hat)).round(4))\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.6609 - accuracy: 0.6152\n",
      "Epoch 2/100\n",
      "460/460 [==============================] - 0s 457us/step - loss: 0.6303 - accuracy: 0.6609\n",
      "Epoch 3/100\n",
      "460/460 [==============================] - 0s 323us/step - loss: 0.5899 - accuracy: 0.7087\n",
      "Epoch 4/100\n",
      "460/460 [==============================] - 0s 330us/step - loss: 0.5804 - accuracy: 0.7087\n",
      "Epoch 5/100\n",
      "460/460 [==============================] - 0s 291us/step - loss: 0.5851 - accuracy: 0.7304\n",
      "Epoch 6/100\n",
      "460/460 [==============================] - 0s 301us/step - loss: 0.5469 - accuracy: 0.7261\n",
      "Epoch 7/100\n",
      "460/460 [==============================] - 0s 293us/step - loss: 0.5323 - accuracy: 0.7478\n",
      "Epoch 8/100\n",
      "460/460 [==============================] - 0s 321us/step - loss: 0.5329 - accuracy: 0.7500\n",
      "Epoch 9/100\n",
      "460/460 [==============================] - 0s 310us/step - loss: 0.5369 - accuracy: 0.7522\n",
      "Epoch 10/100\n",
      "460/460 [==============================] - 0s 297us/step - loss: 0.5453 - accuracy: 0.7348\n",
      "Epoch 11/100\n",
      "460/460 [==============================] - 0s 295us/step - loss: 0.5383 - accuracy: 0.7348\n",
      "Epoch 12/100\n",
      "460/460 [==============================] - 0s 319us/step - loss: 0.5536 - accuracy: 0.7196\n",
      "Epoch 13/100\n",
      "460/460 [==============================] - 0s 306us/step - loss: 0.5104 - accuracy: 0.7370\n",
      "Epoch 14/100\n",
      "460/460 [==============================] - 0s 299us/step - loss: 0.4966 - accuracy: 0.7478\n",
      "Epoch 15/100\n",
      "460/460 [==============================] - 0s 336us/step - loss: 0.5227 - accuracy: 0.7457\n",
      "Epoch 16/100\n",
      "460/460 [==============================] - 0s 291us/step - loss: 0.5129 - accuracy: 0.7543\n",
      "Epoch 17/100\n",
      "460/460 [==============================] - 0s 306us/step - loss: 0.5050 - accuracy: 0.7522\n",
      "Epoch 18/100\n",
      "460/460 [==============================] - 0s 308us/step - loss: 0.5237 - accuracy: 0.7413\n",
      "Epoch 19/100\n",
      "460/460 [==============================] - 0s 310us/step - loss: 0.4965 - accuracy: 0.7565\n",
      "Epoch 20/100\n",
      "460/460 [==============================] - 0s 299us/step - loss: 0.4928 - accuracy: 0.7696\n",
      "Epoch 21/100\n",
      "460/460 [==============================] - 0s 312us/step - loss: 0.5140 - accuracy: 0.7413\n",
      "Epoch 22/100\n",
      "460/460 [==============================] - 0s 288us/step - loss: 0.4672 - accuracy: 0.7522\n",
      "Epoch 23/100\n",
      "460/460 [==============================] - 0s 306us/step - loss: 0.5133 - accuracy: 0.7413\n",
      "Epoch 24/100\n",
      "460/460 [==============================] - 0s 297us/step - loss: 0.4838 - accuracy: 0.7522\n",
      "Epoch 25/100\n",
      "460/460 [==============================] - 0s 288us/step - loss: 0.5000 - accuracy: 0.7478\n",
      "Epoch 26/100\n",
      "460/460 [==============================] - 0s 308us/step - loss: 0.5032 - accuracy: 0.7283\n",
      "Epoch 27/100\n",
      "460/460 [==============================] - 0s 297us/step - loss: 0.4927 - accuracy: 0.7391\n",
      "Epoch 28/100\n",
      "460/460 [==============================] - 0s 319us/step - loss: 0.4990 - accuracy: 0.7522\n",
      "Epoch 29/100\n",
      "460/460 [==============================] - 0s 314us/step - loss: 0.4896 - accuracy: 0.7435\n",
      "Epoch 30/100\n",
      "460/460 [==============================] - 0s 301us/step - loss: 0.5047 - accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "460/460 [==============================] - 0s 282us/step - loss: 0.4918 - accuracy: 0.7500\n",
      "Epoch 32/100\n",
      "460/460 [==============================] - 0s 293us/step - loss: 0.4942 - accuracy: 0.7391\n",
      "Epoch 33/100\n",
      "460/460 [==============================] - 0s 323us/step - loss: 0.4755 - accuracy: 0.7370\n",
      "Epoch 34/100\n",
      "460/460 [==============================] - 0s 293us/step - loss: 0.4877 - accuracy: 0.7370\n",
      "Epoch 35/100\n",
      "460/460 [==============================] - 0s 317us/step - loss: 0.5197 - accuracy: 0.7304\n",
      "Epoch 36/100\n",
      "460/460 [==============================] - 0s 293us/step - loss: 0.4834 - accuracy: 0.7348\n",
      "Epoch 37/100\n",
      "460/460 [==============================] - 0s 314us/step - loss: 0.4984 - accuracy: 0.7500\n",
      "Epoch 38/100\n",
      "460/460 [==============================] - 0s 301us/step - loss: 0.4892 - accuracy: 0.7413\n",
      "Epoch 39/100\n",
      "460/460 [==============================] - 0s 301us/step - loss: 0.5101 - accuracy: 0.7543\n",
      "Epoch 40/100\n",
      "460/460 [==============================] - 0s 308us/step - loss: 0.4965 - accuracy: 0.7239\n",
      "Epoch 41/100\n",
      "460/460 [==============================] - 0s 301us/step - loss: 0.4767 - accuracy: 0.7457\n",
      "Epoch 42/100\n",
      "460/460 [==============================] - 0s 334us/step - loss: 0.4908 - accuracy: 0.7370\n",
      "Epoch 43/100\n",
      "460/460 [==============================] - 0s 316us/step - loss: 0.4878 - accuracy: 0.7261\n",
      "Epoch 44/100\n",
      "460/460 [==============================] - 0s 375us/step - loss: 0.4849 - accuracy: 0.7283\n",
      "Epoch 45/100\n",
      "460/460 [==============================] - 0s 425us/step - loss: 0.4728 - accuracy: 0.7326\n",
      "Epoch 46/100\n",
      "460/460 [==============================] - 0s 323us/step - loss: 0.4854 - accuracy: 0.7652\n",
      "Epoch 47/100\n",
      "460/460 [==============================] - 0s 301us/step - loss: 0.4877 - accuracy: 0.7522\n",
      "Epoch 48/100\n",
      "460/460 [==============================] - 0s 375us/step - loss: 0.4593 - accuracy: 0.7435\n",
      "Epoch 49/100\n",
      "460/460 [==============================] - 0s 373us/step - loss: 0.4819 - accuracy: 0.7348\n",
      "Epoch 50/100\n",
      "460/460 [==============================] - 0s 299us/step - loss: 0.4757 - accuracy: 0.7630\n",
      "Epoch 51/100\n",
      "460/460 [==============================] - 0s 301us/step - loss: 0.4770 - accuracy: 0.7261\n",
      "Epoch 52/100\n",
      "460/460 [==============================] - 0s 310us/step - loss: 0.5020 - accuracy: 0.7239\n",
      "Epoch 53/100\n",
      "460/460 [==============================] - 0s 373us/step - loss: 0.5137 - accuracy: 0.7196\n",
      "Epoch 54/100\n",
      "460/460 [==============================] - 0s 364us/step - loss: 0.5031 - accuracy: 0.7109\n",
      "Epoch 55/100\n",
      "460/460 [==============================] - 0s 288us/step - loss: 0.4732 - accuracy: 0.7609\n",
      "Epoch 56/100\n",
      "460/460 [==============================] - 0s 317us/step - loss: 0.4673 - accuracy: 0.7413\n",
      "Epoch 57/100\n",
      "460/460 [==============================] - 0s 364us/step - loss: 0.4942 - accuracy: 0.7435\n",
      "Epoch 58/100\n",
      "460/460 [==============================] - 0s 317us/step - loss: 0.4649 - accuracy: 0.7500\n",
      "Epoch 59/100\n",
      "460/460 [==============================] - 0s 299us/step - loss: 0.5029 - accuracy: 0.7457\n",
      "Epoch 60/100\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.4622 - accuracy: 0.73 - 0s 301us/step - loss: 0.4736 - accuracy: 0.7435\n",
      "Epoch 61/100\n",
      "460/460 [==============================] - 0s 377us/step - loss: 0.4792 - accuracy: 0.7609\n",
      "Epoch 62/100\n",
      "460/460 [==============================] - 0s 297us/step - loss: 0.4829 - accuracy: 0.7674\n",
      "Epoch 63/100\n",
      "460/460 [==============================] - 0s 301us/step - loss: 0.4756 - accuracy: 0.7739\n",
      "Epoch 64/100\n",
      "460/460 [==============================] - 0s 340us/step - loss: 0.4673 - accuracy: 0.7391\n",
      "Epoch 65/100\n",
      "460/460 [==============================] - 0s 297us/step - loss: 0.4715 - accuracy: 0.7435\n",
      "Epoch 66/100\n",
      "460/460 [==============================] - 0s 332us/step - loss: 0.4838 - accuracy: 0.7326\n",
      "Epoch 67/100\n",
      "460/460 [==============================] - 0s 297us/step - loss: 0.4732 - accuracy: 0.7348\n",
      "Epoch 68/100\n",
      "460/460 [==============================] - 0s 299us/step - loss: 0.4647 - accuracy: 0.7413\n",
      "Epoch 69/100\n",
      "460/460 [==============================] - 0s 297us/step - loss: 0.4736 - accuracy: 0.7391\n",
      "Epoch 70/100\n",
      "460/460 [==============================] - 0s 334us/step - loss: 0.4792 - accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "460/460 [==============================] - 0s 308us/step - loss: 0.4559 - accuracy: 0.7609\n",
      "Epoch 72/100\n",
      "460/460 [==============================] - 0s 306us/step - loss: 0.4933 - accuracy: 0.7326\n",
      "Epoch 73/100\n",
      "460/460 [==============================] - 0s 384us/step - loss: 0.4716 - accuracy: 0.7630\n",
      "Epoch 74/100\n",
      "460/460 [==============================] - 0s 395us/step - loss: 0.4865 - accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "460/460 [==============================] - 0s 310us/step - loss: 0.4795 - accuracy: 0.7152\n",
      "Epoch 76/100\n",
      "460/460 [==============================] - 0s 332us/step - loss: 0.4755 - accuracy: 0.7348\n",
      "Epoch 77/100\n",
      "460/460 [==============================] - 0s 308us/step - loss: 0.4646 - accuracy: 0.7652\n",
      "Epoch 78/100\n",
      "460/460 [==============================] - 0s 306us/step - loss: 0.4695 - accuracy: 0.7326\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460/460 [==============================] - 0s 293us/step - loss: 0.4654 - accuracy: 0.7435\n",
      "Epoch 80/100\n",
      "460/460 [==============================] - 0s 319us/step - loss: 0.4928 - accuracy: 0.7391\n",
      "Epoch 81/100\n",
      "460/460 [==============================] - 0s 319us/step - loss: 0.4804 - accuracy: 0.7152\n",
      "Epoch 82/100\n",
      "460/460 [==============================] - 0s 282us/step - loss: 0.4890 - accuracy: 0.7326\n",
      "Epoch 83/100\n",
      "460/460 [==============================] - 0s 282us/step - loss: 0.4950 - accuracy: 0.7261\n",
      "Epoch 84/100\n",
      "460/460 [==============================] - 0s 321us/step - loss: 0.4793 - accuracy: 0.7413\n",
      "Epoch 85/100\n",
      "460/460 [==============================] - 0s 338us/step - loss: 0.4642 - accuracy: 0.7087\n",
      "Epoch 86/100\n",
      "460/460 [==============================] - 0s 284us/step - loss: 0.4695 - accuracy: 0.7457\n",
      "Epoch 87/100\n",
      "460/460 [==============================] - 0s 288us/step - loss: 0.4847 - accuracy: 0.7391\n",
      "Epoch 88/100\n",
      "460/460 [==============================] - 0s 297us/step - loss: 0.4709 - accuracy: 0.7391\n",
      "Epoch 89/100\n",
      "460/460 [==============================] - 0s 314us/step - loss: 0.5070 - accuracy: 0.7696\n",
      "Epoch 90/100\n",
      "460/460 [==============================] - 0s 288us/step - loss: 0.4788 - accuracy: 0.7370\n",
      "Epoch 91/100\n",
      "460/460 [==============================] - 0s 286us/step - loss: 0.4483 - accuracy: 0.7565\n",
      "Epoch 92/100\n",
      "460/460 [==============================] - 0s 299us/step - loss: 0.4884 - accuracy: 0.7478\n",
      "Epoch 93/100\n",
      "460/460 [==============================] - 0s 293us/step - loss: 0.4828 - accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "460/460 [==============================] - 0s 288us/step - loss: 0.4812 - accuracy: 0.7435\n",
      "Epoch 95/100\n",
      "460/460 [==============================] - 0s 301us/step - loss: 0.4807 - accuracy: 0.7413\n",
      "Epoch 96/100\n",
      "460/460 [==============================] - 0s 284us/step - loss: 0.4943 - accuracy: 0.7109\n",
      "Epoch 97/100\n",
      "460/460 [==============================] - 0s 312us/step - loss: 0.4702 - accuracy: 0.7435\n",
      "Epoch 98/100\n",
      "460/460 [==============================] - 0s 275us/step - loss: 0.4689 - accuracy: 0.7587\n",
      "Epoch 99/100\n",
      "460/460 [==============================] - 0s 291us/step - loss: 0.4762 - accuracy: 0.7587\n",
      "Epoch 100/100\n",
      "460/460 [==============================] - 0s 366us/step - loss: 0.4896 - accuracy: 0.7196\n",
      "Epoch 1/100\n",
      "461/461 [==============================] - 1s 2ms/step - loss: 0.6642 - accuracy: 0.5705\n",
      "Epoch 2/100\n",
      "461/461 [==============================] - 0s 398us/step - loss: 0.6101 - accuracy: 0.6551\n",
      "Epoch 3/100\n",
      "461/461 [==============================] - 0s 394us/step - loss: 0.5888 - accuracy: 0.6790\n",
      "Epoch 4/100\n",
      "461/461 [==============================] - 0s 292us/step - loss: 0.5786 - accuracy: 0.6616\n",
      "Epoch 5/100\n",
      "461/461 [==============================] - 0s 443us/step - loss: 0.5746 - accuracy: 0.7093\n",
      "Epoch 6/100\n",
      "461/461 [==============================] - 0s 415us/step - loss: 0.5452 - accuracy: 0.7050\n",
      "Epoch 7/100\n",
      "461/461 [==============================] - 0s 454us/step - loss: 0.5462 - accuracy: 0.7050\n",
      "Epoch 8/100\n",
      "461/461 [==============================] - 0s 439us/step - loss: 0.5639 - accuracy: 0.7007\n",
      "Epoch 9/100\n",
      "461/461 [==============================] - 0s 450us/step - loss: 0.5460 - accuracy: 0.7050\n",
      "Epoch 10/100\n",
      "461/461 [==============================] - 0s 443us/step - loss: 0.5431 - accuracy: 0.7115\n",
      "Epoch 11/100\n",
      "461/461 [==============================] - 0s 697us/step - loss: 0.5321 - accuracy: 0.7137\n",
      "Epoch 12/100\n",
      "461/461 [==============================] - 0s 472us/step - loss: 0.5422 - accuracy: 0.7007\n",
      "Epoch 13/100\n",
      "461/461 [==============================] - 0s 443us/step - loss: 0.5225 - accuracy: 0.6985\n",
      "Epoch 14/100\n",
      "461/461 [==============================] - 0s 476us/step - loss: 0.5178 - accuracy: 0.7180\n",
      "Epoch 15/100\n",
      "461/461 [==============================] - 0s 461us/step - loss: 0.5370 - accuracy: 0.7267\n",
      "Epoch 16/100\n",
      "461/461 [==============================] - 0s 437us/step - loss: 0.5159 - accuracy: 0.7332\n",
      "Epoch 17/100\n",
      "461/461 [==============================] - 0s 435us/step - loss: 0.5121 - accuracy: 0.7267\n",
      "Epoch 18/100\n",
      "461/461 [==============================] - 0s 480us/step - loss: 0.5191 - accuracy: 0.7332\n",
      "Epoch 19/100\n",
      "461/461 [==============================] - 0s 474us/step - loss: 0.5046 - accuracy: 0.7440\n",
      "Epoch 20/100\n",
      "461/461 [==============================] - 0s 448us/step - loss: 0.5434 - accuracy: 0.7158\n",
      "Epoch 21/100\n",
      "461/461 [==============================] - 0s 443us/step - loss: 0.5197 - accuracy: 0.7484\n",
      "Epoch 22/100\n",
      "461/461 [==============================] - 0s 415us/step - loss: 0.5159 - accuracy: 0.7636\n",
      "Epoch 23/100\n",
      "461/461 [==============================] - 0s 428us/step - loss: 0.4973 - accuracy: 0.7570\n",
      "Epoch 24/100\n",
      "461/461 [==============================] - 0s 426us/step - loss: 0.4988 - accuracy: 0.7484\n",
      "Epoch 25/100\n",
      "461/461 [==============================] - 0s 413us/step - loss: 0.4757 - accuracy: 0.7419\n",
      "Epoch 26/100\n",
      "461/461 [==============================] - 0s 426us/step - loss: 0.4958 - accuracy: 0.7354\n",
      "Epoch 27/100\n",
      "461/461 [==============================] - 0s 437us/step - loss: 0.4896 - accuracy: 0.7375\n",
      "Epoch 28/100\n",
      "461/461 [==============================] - 0s 426us/step - loss: 0.4999 - accuracy: 0.7267\n",
      "Epoch 29/100\n",
      "461/461 [==============================] - 0s 363us/step - loss: 0.4956 - accuracy: 0.7592\n",
      "Epoch 30/100\n",
      "461/461 [==============================] - 0s 309us/step - loss: 0.5036 - accuracy: 0.7462\n",
      "Epoch 31/100\n",
      "461/461 [==============================] - 0s 340us/step - loss: 0.5339 - accuracy: 0.7310\n",
      "Epoch 32/100\n",
      "461/461 [==============================] - 0s 320us/step - loss: 0.5108 - accuracy: 0.7310\n",
      "Epoch 33/100\n",
      "461/461 [==============================] - 0s 331us/step - loss: 0.5011 - accuracy: 0.7397\n",
      "Epoch 34/100\n",
      "461/461 [==============================] - 0s 342us/step - loss: 0.4952 - accuracy: 0.7354\n",
      "Epoch 35/100\n",
      "461/461 [==============================] - 0s 493us/step - loss: 0.5218 - accuracy: 0.7245\n",
      "Epoch 36/100\n",
      "461/461 [==============================] - 0s 418us/step - loss: 0.5122 - accuracy: 0.7397\n",
      "Epoch 37/100\n",
      "461/461 [==============================] - 0s 333us/step - loss: 0.4956 - accuracy: 0.7549\n",
      "Epoch 38/100\n",
      "461/461 [==============================] - 0s 402us/step - loss: 0.4835 - accuracy: 0.7505\n",
      "Epoch 39/100\n",
      "461/461 [==============================] - 0s 316us/step - loss: 0.5138 - accuracy: 0.7549\n",
      "Epoch 40/100\n",
      "461/461 [==============================] - 0s 316us/step - loss: 0.4879 - accuracy: 0.7657\n",
      "Epoch 41/100\n",
      "461/461 [==============================] - 0s 307us/step - loss: 0.4830 - accuracy: 0.7766\n",
      "Epoch 42/100\n",
      "461/461 [==============================] - 0s 320us/step - loss: 0.4852 - accuracy: 0.7614\n",
      "Epoch 43/100\n",
      "461/461 [==============================] - 0s 294us/step - loss: 0.4944 - accuracy: 0.7701\n",
      "Epoch 44/100\n",
      "461/461 [==============================] - 0s 318us/step - loss: 0.4901 - accuracy: 0.7570\n",
      "Epoch 45/100\n",
      "461/461 [==============================] - 0s 337us/step - loss: 0.4812 - accuracy: 0.7787\n",
      "Epoch 46/100\n",
      "461/461 [==============================] - 0s 363us/step - loss: 0.5114 - accuracy: 0.7527\n",
      "Epoch 47/100\n",
      "461/461 [==============================] - 0s 309us/step - loss: 0.5042 - accuracy: 0.7636\n",
      "Epoch 48/100\n",
      "461/461 [==============================] - 0s 314us/step - loss: 0.4779 - accuracy: 0.7831\n",
      "Epoch 49/100\n",
      "461/461 [==============================] - 0s 320us/step - loss: 0.4843 - accuracy: 0.7679\n",
      "Epoch 50/100\n",
      "461/461 [==============================] - 0s 314us/step - loss: 0.4788 - accuracy: 0.7549\n",
      "Epoch 51/100\n",
      "461/461 [==============================] - 0s 325us/step - loss: 0.5121 - accuracy: 0.7679\n",
      "Epoch 52/100\n",
      "461/461 [==============================] - 0s 357us/step - loss: 0.5011 - accuracy: 0.7744\n",
      "Epoch 53/100\n",
      "461/461 [==============================] - 0s 344us/step - loss: 0.4932 - accuracy: 0.7592\n",
      "Epoch 54/100\n",
      "461/461 [==============================] - 0s 331us/step - loss: 0.4716 - accuracy: 0.7961\n",
      "Epoch 55/100\n",
      "461/461 [==============================] - 0s 333us/step - loss: 0.4713 - accuracy: 0.7809\n",
      "Epoch 56/100\n",
      "461/461 [==============================] - 0s 301us/step - loss: 0.5082 - accuracy: 0.7701\n",
      "Epoch 57/100\n",
      "461/461 [==============================] - 0s 372us/step - loss: 0.4768 - accuracy: 0.7657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "461/461 [==============================] - 0s 309us/step - loss: 0.4808 - accuracy: 0.7874\n",
      "Epoch 59/100\n",
      "461/461 [==============================] - 0s 305us/step - loss: 0.5033 - accuracy: 0.7744\n",
      "Epoch 60/100\n",
      "461/461 [==============================] - 0s 307us/step - loss: 0.4642 - accuracy: 0.7636\n",
      "Epoch 61/100\n",
      "461/461 [==============================] - 0s 318us/step - loss: 0.4794 - accuracy: 0.7809\n",
      "Epoch 62/100\n",
      "461/461 [==============================] - 0s 301us/step - loss: 0.4727 - accuracy: 0.7939\n",
      "Epoch 63/100\n",
      "461/461 [==============================] - 0s 307us/step - loss: 0.4729 - accuracy: 0.7766\n",
      "Epoch 64/100\n",
      "461/461 [==============================] - 0s 303us/step - loss: 0.4820 - accuracy: 0.7787\n",
      "Epoch 65/100\n",
      "461/461 [==============================] - 0s 355us/step - loss: 0.4896 - accuracy: 0.7874\n",
      "Epoch 66/100\n",
      "461/461 [==============================] - 0s 312us/step - loss: 0.4812 - accuracy: 0.7701\n",
      "Epoch 67/100\n",
      "461/461 [==============================] - 0s 292us/step - loss: 0.4705 - accuracy: 0.7896\n",
      "Epoch 68/100\n",
      "461/461 [==============================] - 0s 305us/step - loss: 0.4887 - accuracy: 0.7679\n",
      "Epoch 69/100\n",
      "461/461 [==============================] - 0s 327us/step - loss: 0.4629 - accuracy: 0.7874\n",
      "Epoch 70/100\n",
      "461/461 [==============================] - 0s 342us/step - loss: 0.4964 - accuracy: 0.7787\n",
      "Epoch 71/100\n",
      "461/461 [==============================] - 0s 370us/step - loss: 0.4871 - accuracy: 0.7636\n",
      "Epoch 72/100\n",
      "461/461 [==============================] - 0s 398us/step - loss: 0.5007 - accuracy: 0.7484\n",
      "Epoch 73/100\n",
      "461/461 [==============================] - 0s 385us/step - loss: 0.4958 - accuracy: 0.7570\n",
      "Epoch 74/100\n",
      "461/461 [==============================] - 0s 476us/step - loss: 0.5072 - accuracy: 0.7636\n",
      "Epoch 75/100\n",
      "461/461 [==============================] - 0s 485us/step - loss: 0.4494 - accuracy: 0.7939\n",
      "Epoch 76/100\n",
      "461/461 [==============================] - 0s 368us/step - loss: 0.4634 - accuracy: 0.7852\n",
      "Epoch 77/100\n",
      "461/461 [==============================] - 0s 426us/step - loss: 0.4633 - accuracy: 0.7809\n",
      "Epoch 78/100\n",
      "461/461 [==============================] - 0s 374us/step - loss: 0.4646 - accuracy: 0.7701\n",
      "Epoch 79/100\n",
      "461/461 [==============================] - 0s 420us/step - loss: 0.4810 - accuracy: 0.7722\n",
      "Epoch 80/100\n",
      "461/461 [==============================] - 0s 431us/step - loss: 0.4767 - accuracy: 0.7787\n",
      "Epoch 81/100\n",
      "461/461 [==============================] - 0s 376us/step - loss: 0.4812 - accuracy: 0.7766\n",
      "Epoch 82/100\n",
      "461/461 [==============================] - 0s 383us/step - loss: 0.4849 - accuracy: 0.7809\n",
      "Epoch 83/100\n",
      "461/461 [==============================] - 0s 385us/step - loss: 0.4708 - accuracy: 0.7983\n",
      "Epoch 84/100\n",
      "461/461 [==============================] - 0s 485us/step - loss: 0.4539 - accuracy: 0.7809\n",
      "Epoch 85/100\n",
      "461/461 [==============================] - 0s 322us/step - loss: 0.4696 - accuracy: 0.7918\n",
      "Epoch 86/100\n",
      "461/461 [==============================] - 0s 325us/step - loss: 0.4730 - accuracy: 0.7809\n",
      "Epoch 87/100\n",
      "461/461 [==============================] - 0s 305us/step - loss: 0.4854 - accuracy: 0.7852\n",
      "Epoch 88/100\n",
      "461/461 [==============================] - 0s 325us/step - loss: 0.4657 - accuracy: 0.7852\n",
      "Epoch 89/100\n",
      "461/461 [==============================] - 0s 381us/step - loss: 0.4674 - accuracy: 0.7852\n",
      "Epoch 90/100\n",
      "461/461 [==============================] - 0s 309us/step - loss: 0.4777 - accuracy: 0.7831\n",
      "Epoch 91/100\n",
      "461/461 [==============================] - 0s 296us/step - loss: 0.4778 - accuracy: 0.7874\n",
      "Epoch 92/100\n",
      "461/461 [==============================] - 0s 340us/step - loss: 0.4611 - accuracy: 0.7961\n",
      "Epoch 93/100\n",
      "461/461 [==============================] - 0s 299us/step - loss: 0.4853 - accuracy: 0.7679\n",
      "Epoch 94/100\n",
      "461/461 [==============================] - 0s 325us/step - loss: 0.4617 - accuracy: 0.7874\n",
      "Epoch 95/100\n",
      "461/461 [==============================] - 0s 299us/step - loss: 0.4682 - accuracy: 0.7809\n",
      "Epoch 96/100\n",
      "461/461 [==============================] - 0s 303us/step - loss: 0.4904 - accuracy: 0.7722\n",
      "Epoch 97/100\n",
      "461/461 [==============================] - 0s 307us/step - loss: 0.4628 - accuracy: 0.7896\n",
      "Epoch 98/100\n",
      "461/461 [==============================] - 0s 318us/step - loss: 0.4661 - accuracy: 0.7852\n",
      "Epoch 99/100\n",
      "461/461 [==============================] - 0s 309us/step - loss: 0.4563 - accuracy: 0.7939\n",
      "Epoch 100/100\n",
      "461/461 [==============================] - 0s 309us/step - loss: 0.4564 - accuracy: 0.7939\n",
      "Epoch 1/100\n",
      "461/461 [==============================] - 1s 2ms/step - loss: 0.6558 - accuracy: 0.6356\n",
      "Epoch 2/100\n",
      "461/461 [==============================] - 0s 325us/step - loss: 0.5975 - accuracy: 0.6508\n",
      "Epoch 3/100\n",
      "461/461 [==============================] - 0s 299us/step - loss: 0.5673 - accuracy: 0.6594\n",
      "Epoch 4/100\n",
      "461/461 [==============================] - 0s 316us/step - loss: 0.5785 - accuracy: 0.6681\n",
      "Epoch 5/100\n",
      "461/461 [==============================] - 0s 292us/step - loss: 0.5601 - accuracy: 0.6833\n",
      "Epoch 6/100\n",
      "461/461 [==============================] - 0s 340us/step - loss: 0.5490 - accuracy: 0.7072\n",
      "Epoch 7/100\n",
      "461/461 [==============================] - 0s 355us/step - loss: 0.5425 - accuracy: 0.6963\n",
      "Epoch 8/100\n",
      "461/461 [==============================] - 0s 396us/step - loss: 0.5114 - accuracy: 0.7007\n",
      "Epoch 9/100\n",
      "461/461 [==============================] - 0s 361us/step - loss: 0.5313 - accuracy: 0.7484\n",
      "Epoch 10/100\n",
      "461/461 [==============================] - 0s 394us/step - loss: 0.5265 - accuracy: 0.7397\n",
      "Epoch 11/100\n",
      "461/461 [==============================] - 0s 409us/step - loss: 0.5199 - accuracy: 0.7158\n",
      "Epoch 12/100\n",
      "461/461 [==============================] - 0s 370us/step - loss: 0.5230 - accuracy: 0.7527\n",
      "Epoch 13/100\n",
      "461/461 [==============================] - 0s 318us/step - loss: 0.5256 - accuracy: 0.7289\n",
      "Epoch 14/100\n",
      "461/461 [==============================] - 0s 327us/step - loss: 0.5113 - accuracy: 0.7158\n",
      "Epoch 15/100\n",
      "461/461 [==============================] - 0s 320us/step - loss: 0.5231 - accuracy: 0.7310\n",
      "Epoch 16/100\n",
      "461/461 [==============================] - 0s 322us/step - loss: 0.5100 - accuracy: 0.7484\n",
      "Epoch 17/100\n",
      "461/461 [==============================] - 0s 305us/step - loss: 0.4902 - accuracy: 0.7636\n",
      "Epoch 18/100\n",
      "461/461 [==============================] - 0s 370us/step - loss: 0.5036 - accuracy: 0.7636\n",
      "Epoch 19/100\n",
      "461/461 [==============================] - 0s 353us/step - loss: 0.5020 - accuracy: 0.7592\n",
      "Epoch 20/100\n",
      "461/461 [==============================] - 0s 309us/step - loss: 0.4869 - accuracy: 0.7766\n",
      "Epoch 21/100\n",
      "461/461 [==============================] - 0s 322us/step - loss: 0.4758 - accuracy: 0.7722\n",
      "Epoch 22/100\n",
      "461/461 [==============================] - 0s 305us/step - loss: 0.5237 - accuracy: 0.7419\n",
      "Epoch 23/100\n",
      "461/461 [==============================] - 0s 392us/step - loss: 0.4720 - accuracy: 0.7592\n",
      "Epoch 24/100\n",
      "461/461 [==============================] - 0s 342us/step - loss: 0.4710 - accuracy: 0.7636\n",
      "Epoch 25/100\n",
      "461/461 [==============================] - 0s 301us/step - loss: 0.4828 - accuracy: 0.7636\n",
      "Epoch 26/100\n",
      "461/461 [==============================] - 0s 342us/step - loss: 0.4906 - accuracy: 0.7570\n",
      "Epoch 27/100\n",
      "461/461 [==============================] - 0s 322us/step - loss: 0.4904 - accuracy: 0.7462\n",
      "Epoch 28/100\n",
      "461/461 [==============================] - 0s 407us/step - loss: 0.4726 - accuracy: 0.7614\n",
      "Epoch 29/100\n",
      "461/461 [==============================] - 0s 359us/step - loss: 0.4935 - accuracy: 0.7549\n",
      "Epoch 30/100\n",
      "461/461 [==============================] - 0s 322us/step - loss: 0.4967 - accuracy: 0.7397\n",
      "Epoch 31/100\n",
      "461/461 [==============================] - 0s 314us/step - loss: 0.4841 - accuracy: 0.7440\n",
      "Epoch 32/100\n",
      "461/461 [==============================] - 0s 340us/step - loss: 0.4709 - accuracy: 0.7787\n",
      "Epoch 33/100\n",
      "461/461 [==============================] - 0s 309us/step - loss: 0.4835 - accuracy: 0.7527\n",
      "Epoch 34/100\n",
      "461/461 [==============================] - 0s 363us/step - loss: 0.4850 - accuracy: 0.7722\n",
      "Epoch 35/100\n",
      "461/461 [==============================] - 0s 316us/step - loss: 0.4988 - accuracy: 0.7636\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461/461 [==============================] - 0s 305us/step - loss: 0.4709 - accuracy: 0.7787\n",
      "Epoch 37/100\n",
      "461/461 [==============================] - 0s 290us/step - loss: 0.4802 - accuracy: 0.7918\n",
      "Epoch 38/100\n",
      "461/461 [==============================] - 0s 329us/step - loss: 0.4889 - accuracy: 0.7701\n",
      "Epoch 39/100\n",
      "461/461 [==============================] - 0s 305us/step - loss: 0.4742 - accuracy: 0.7874\n",
      "Epoch 40/100\n",
      "461/461 [==============================] - 0s 288us/step - loss: 0.4627 - accuracy: 0.7787\n",
      "Epoch 41/100\n",
      "461/461 [==============================] - 0s 515us/step - loss: 0.4666 - accuracy: 0.7852\n",
      "Epoch 42/100\n",
      "461/461 [==============================] - 0s 554us/step - loss: 0.4776 - accuracy: 0.7809\n",
      "Epoch 43/100\n",
      "461/461 [==============================] - 0s 567us/step - loss: 0.4987 - accuracy: 0.7787\n",
      "Epoch 44/100\n",
      "461/461 [==============================] - 0s 474us/step - loss: 0.4645 - accuracy: 0.7896\n",
      "Epoch 45/100\n",
      "461/461 [==============================] - 0s 443us/step - loss: 0.4864 - accuracy: 0.7701\n",
      "Epoch 46/100\n",
      "461/461 [==============================] - 0s 441us/step - loss: 0.4517 - accuracy: 0.7918\n",
      "Epoch 47/100\n",
      "461/461 [==============================] - 0s 420us/step - loss: 0.4489 - accuracy: 0.8069\n",
      "Epoch 48/100\n",
      "461/461 [==============================] - 0s 433us/step - loss: 0.4556 - accuracy: 0.7983\n",
      "Epoch 49/100\n",
      "461/461 [==============================] - 0s 452us/step - loss: 0.4553 - accuracy: 0.8004\n",
      "Epoch 50/100\n",
      "461/461 [==============================] - 0s 528us/step - loss: 0.4755 - accuracy: 0.7636\n",
      "Epoch 51/100\n",
      "461/461 [==============================] - 0s 495us/step - loss: 0.4680 - accuracy: 0.7701\n",
      "Epoch 52/100\n",
      "461/461 [==============================] - 0s 480us/step - loss: 0.4607 - accuracy: 0.7874\n",
      "Epoch 53/100\n",
      "461/461 [==============================] - 0s 439us/step - loss: 0.4568 - accuracy: 0.7983\n",
      "Epoch 54/100\n",
      "461/461 [==============================] - 0s 513us/step - loss: 0.4839 - accuracy: 0.7939\n",
      "Epoch 55/100\n",
      "461/461 [==============================] - 0s 450us/step - loss: 0.4546 - accuracy: 0.7918\n",
      "Epoch 56/100\n",
      "461/461 [==============================] - 0s 439us/step - loss: 0.4670 - accuracy: 0.7983\n",
      "Epoch 57/100\n",
      "461/461 [==============================] - 0s 418us/step - loss: 0.4589 - accuracy: 0.7961\n",
      "Epoch 58/100\n",
      "461/461 [==============================] - 0s 431us/step - loss: 0.4762 - accuracy: 0.8004\n",
      "Epoch 59/100\n",
      "461/461 [==============================] - 0s 454us/step - loss: 0.4634 - accuracy: 0.7939\n",
      "Epoch 60/100\n",
      "461/461 [==============================] - 0s 591us/step - loss: 0.4668 - accuracy: 0.8048\n",
      "Epoch 61/100\n",
      "461/461 [==============================] - 0s 529us/step - loss: 0.4892 - accuracy: 0.7831\n",
      "Epoch 62/100\n",
      "461/461 [==============================] - 0s 442us/step - loss: 0.4779 - accuracy: 0.7787\n",
      "Epoch 63/100\n",
      "461/461 [==============================] - 0s 452us/step - loss: 0.4562 - accuracy: 0.7852\n",
      "Epoch 64/100\n",
      "461/461 [==============================] - 0s 448us/step - loss: 0.4592 - accuracy: 0.7874\n",
      "Epoch 65/100\n",
      "461/461 [==============================] - 0s 472us/step - loss: 0.4391 - accuracy: 0.8069\n",
      "Epoch 66/100\n",
      "461/461 [==============================] - 0s 395us/step - loss: 0.4505 - accuracy: 0.7961\n",
      "Epoch 67/100\n",
      "461/461 [==============================] - 0s 407us/step - loss: 0.4777 - accuracy: 0.7983\n",
      "Epoch 68/100\n",
      "461/461 [==============================] - 0s 601us/step - loss: 0.4629 - accuracy: 0.7983\n",
      "Epoch 69/100\n",
      "461/461 [==============================] - 0s 558us/step - loss: 0.4497 - accuracy: 0.7939\n",
      "Epoch 70/100\n",
      "461/461 [==============================] - 0s 569us/step - loss: 0.4900 - accuracy: 0.8048\n",
      "Epoch 71/100\n",
      "461/461 [==============================] - 0s 608us/step - loss: 0.4589 - accuracy: 0.7961\n",
      "Epoch 72/100\n",
      "461/461 [==============================] - 0s 674us/step - loss: 0.4761 - accuracy: 0.7701\n",
      "Epoch 73/100\n",
      "461/461 [==============================] - 0s 580us/step - loss: 0.4623 - accuracy: 0.7918\n",
      "Epoch 74/100\n",
      "461/461 [==============================] - 0s 517us/step - loss: 0.4511 - accuracy: 0.7918\n",
      "Epoch 75/100\n",
      "461/461 [==============================] - 0s 444us/step - loss: 0.4519 - accuracy: 0.8026\n",
      "Epoch 76/100\n",
      "461/461 [==============================] - 0s 610us/step - loss: 0.4725 - accuracy: 0.7874\n",
      "Epoch 77/100\n",
      "461/461 [==============================] - 0s 534us/step - loss: 0.4637 - accuracy: 0.7918\n",
      "Epoch 78/100\n",
      "461/461 [==============================] - 0s 550us/step - loss: 0.4676 - accuracy: 0.7896\n",
      "Epoch 79/100\n",
      "461/461 [==============================] - 0s 599us/step - loss: 0.4605 - accuracy: 0.7961\n",
      "Epoch 80/100\n",
      "461/461 [==============================] - 0s 541us/step - loss: 0.4590 - accuracy: 0.8004\n",
      "Epoch 81/100\n",
      "461/461 [==============================] - 0s 456us/step - loss: 0.4608 - accuracy: 0.7831\n",
      "Epoch 82/100\n",
      "461/461 [==============================] - 0s 433us/step - loss: 0.4504 - accuracy: 0.7874\n",
      "Epoch 83/100\n",
      "461/461 [==============================] - 0s 443us/step - loss: 0.4710 - accuracy: 0.7939\n",
      "Epoch 84/100\n",
      "461/461 [==============================] - 0s 446us/step - loss: 0.4513 - accuracy: 0.7983\n",
      "Epoch 85/100\n",
      "461/461 [==============================] - 0s 463us/step - loss: 0.4621 - accuracy: 0.7701\n",
      "Epoch 86/100\n",
      "461/461 [==============================] - 0s 463us/step - loss: 0.4389 - accuracy: 0.7939\n",
      "Epoch 87/100\n",
      "461/461 [==============================] - 0s 431us/step - loss: 0.4635 - accuracy: 0.7961\n",
      "Epoch 88/100\n",
      "461/461 [==============================] - 0s 433us/step - loss: 0.4549 - accuracy: 0.8048\n",
      "Epoch 89/100\n",
      "461/461 [==============================] - 0s 433us/step - loss: 0.4255 - accuracy: 0.8134\n",
      "Epoch 90/100\n",
      "461/461 [==============================] - 0s 450us/step - loss: 0.4338 - accuracy: 0.8069\n",
      "Epoch 91/100\n",
      "461/461 [==============================] - 0s 448us/step - loss: 0.4513 - accuracy: 0.8026\n",
      "Epoch 92/100\n",
      "461/461 [==============================] - 0s 357us/step - loss: 0.4485 - accuracy: 0.8091\n",
      "Epoch 93/100\n",
      "461/461 [==============================] - 0s 485us/step - loss: 0.4640 - accuracy: 0.7918\n",
      "Epoch 94/100\n",
      "461/461 [==============================] - 0s 407us/step - loss: 0.4919 - accuracy: 0.7549\n",
      "Epoch 95/100\n",
      "461/461 [==============================] - 0s 539us/step - loss: 0.4687 - accuracy: 0.7961\n",
      "Epoch 96/100\n",
      "461/461 [==============================] - 0s 448us/step - loss: 0.4389 - accuracy: 0.8156\n",
      "Epoch 97/100\n",
      "461/461 [==============================] - 0s 335us/step - loss: 0.4535 - accuracy: 0.7852\n",
      "Epoch 98/100\n",
      "461/461 [==============================] - 0s 407us/step - loss: 0.4499 - accuracy: 0.8048\n",
      "Epoch 99/100\n",
      "461/461 [==============================] - 0s 413us/step - loss: 0.4442 - accuracy: 0.8113\n",
      "Epoch 100/100\n",
      "461/461 [==============================] - 0s 409us/step - loss: 0.4327 - accuracy: 0.8156\n",
      "Epoch 1/100\n",
      "461/461 [==============================] - 1s 1ms/step - loss: 0.6996 - accuracy: 0.5662\n",
      "Epoch 2/100\n",
      "461/461 [==============================] - 0s 210us/step - loss: 0.6337 - accuracy: 0.6703\n",
      "Epoch 3/100\n",
      "461/461 [==============================] - 0s 335us/step - loss: 0.6017 - accuracy: 0.6790\n",
      "Epoch 4/100\n",
      "461/461 [==============================] - 0s 368us/step - loss: 0.6013 - accuracy: 0.6920\n",
      "Epoch 5/100\n",
      "461/461 [==============================] - 0s 376us/step - loss: 0.6017 - accuracy: 0.7093\n",
      "Epoch 6/100\n",
      "461/461 [==============================] - 0s 441us/step - loss: 0.5570 - accuracy: 0.7115\n",
      "Epoch 7/100\n",
      "461/461 [==============================] - 0s 327us/step - loss: 0.5231 - accuracy: 0.7267\n",
      "Epoch 8/100\n",
      "461/461 [==============================] - 0s 307us/step - loss: 0.5413 - accuracy: 0.7310\n",
      "Epoch 9/100\n",
      "461/461 [==============================] - 0s 312us/step - loss: 0.5488 - accuracy: 0.7462\n",
      "Epoch 10/100\n",
      "461/461 [==============================] - 0s 350us/step - loss: 0.5345 - accuracy: 0.7354\n",
      "Epoch 11/100\n",
      "461/461 [==============================] - 0s 418us/step - loss: 0.4986 - accuracy: 0.7419\n",
      "Epoch 12/100\n",
      "461/461 [==============================] - 0s 396us/step - loss: 0.5190 - accuracy: 0.7657\n",
      "Epoch 13/100\n",
      "461/461 [==============================] - 0s 467us/step - loss: 0.5156 - accuracy: 0.7505\n",
      "Epoch 14/100\n",
      "461/461 [==============================] - 0s 357us/step - loss: 0.5131 - accuracy: 0.7636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "461/461 [==============================] - 0s 366us/step - loss: 0.5164 - accuracy: 0.7570\n",
      "Epoch 16/100\n",
      "461/461 [==============================] - 0s 309us/step - loss: 0.5129 - accuracy: 0.7440\n",
      "Epoch 17/100\n",
      "461/461 [==============================] - 0s 327us/step - loss: 0.5008 - accuracy: 0.7570\n",
      "Epoch 18/100\n",
      "461/461 [==============================] - 0s 312us/step - loss: 0.5281 - accuracy: 0.7614\n",
      "Epoch 19/100\n",
      "461/461 [==============================] - 0s 312us/step - loss: 0.4909 - accuracy: 0.7549\n",
      "Epoch 20/100\n",
      "461/461 [==============================] - 0s 292us/step - loss: 0.4916 - accuracy: 0.7527\n",
      "Epoch 21/100\n",
      "461/461 [==============================] - 0s 387us/step - loss: 0.5137 - accuracy: 0.7679\n",
      "Epoch 22/100\n",
      "461/461 [==============================] - 0s 363us/step - loss: 0.5171 - accuracy: 0.75270s - loss: 0.5357 - accuracy: \n",
      "Epoch 23/100\n",
      "461/461 [==============================] - 0s 387us/step - loss: 0.5035 - accuracy: 0.7636\n",
      "Epoch 24/100\n",
      "461/461 [==============================] - 0s 327us/step - loss: 0.4937 - accuracy: 0.7570\n",
      "Epoch 25/100\n",
      "461/461 [==============================] - 0s 312us/step - loss: 0.5149 - accuracy: 0.7549\n",
      "Epoch 26/100\n",
      "461/461 [==============================] - 0s 318us/step - loss: 0.5041 - accuracy: 0.7570\n",
      "Epoch 27/100\n",
      "461/461 [==============================] - 0s 303us/step - loss: 0.5236 - accuracy: 0.7484\n",
      "Epoch 28/100\n",
      "461/461 [==============================] - 0s 292us/step - loss: 0.4971 - accuracy: 0.7570\n",
      "Epoch 29/100\n",
      "461/461 [==============================] - 0s 322us/step - loss: 0.4946 - accuracy: 0.7549\n",
      "Epoch 30/100\n",
      "461/461 [==============================] - 0s 307us/step - loss: 0.4928 - accuracy: 0.7570\n",
      "Epoch 31/100\n",
      "461/461 [==============================] - 0s 303us/step - loss: 0.4868 - accuracy: 0.7722\n",
      "Epoch 32/100\n",
      "461/461 [==============================] - 0s 314us/step - loss: 0.4758 - accuracy: 0.7657\n",
      "Epoch 33/100\n",
      "461/461 [==============================] - 0s 299us/step - loss: 0.4764 - accuracy: 0.7505\n",
      "Epoch 34/100\n",
      "461/461 [==============================] - 0s 303us/step - loss: 0.4910 - accuracy: 0.7744\n",
      "Epoch 35/100\n",
      "461/461 [==============================] - 0s 301us/step - loss: 0.4773 - accuracy: 0.7896\n",
      "Epoch 36/100\n",
      "461/461 [==============================] - ETA: 0s - loss: 0.4868 - accuracy: 0.78 - 0s 320us/step - loss: 0.4919 - accuracy: 0.7701\n",
      "Epoch 37/100\n",
      "461/461 [==============================] - 0s 303us/step - loss: 0.4657 - accuracy: 0.7852\n",
      "Epoch 38/100\n",
      "461/461 [==============================] - 0s 303us/step - loss: 0.5121 - accuracy: 0.7549\n",
      "Epoch 39/100\n",
      "461/461 [==============================] - 0s 318us/step - loss: 0.4830 - accuracy: 0.7636\n",
      "Epoch 40/100\n",
      "461/461 [==============================] - 0s 292us/step - loss: 0.4884 - accuracy: 0.7831\n",
      "Epoch 41/100\n",
      "461/461 [==============================] - 0s 316us/step - loss: 0.4985 - accuracy: 0.7592\n",
      "Epoch 42/100\n",
      "461/461 [==============================] - 0s 301us/step - loss: 0.4699 - accuracy: 0.7722\n",
      "Epoch 43/100\n",
      "461/461 [==============================] - 0s 325us/step - loss: 0.4849 - accuracy: 0.7874\n",
      "Epoch 44/100\n",
      "461/461 [==============================] - 0s 309us/step - loss: 0.4770 - accuracy: 0.7679\n",
      "Epoch 45/100\n",
      "461/461 [==============================] - 0s 314us/step - loss: 0.5002 - accuracy: 0.7744\n",
      "Epoch 46/100\n",
      "461/461 [==============================] - 0s 299us/step - loss: 0.4945 - accuracy: 0.7462\n",
      "Epoch 47/100\n",
      "461/461 [==============================] - 0s 301us/step - loss: 0.4701 - accuracy: 0.7614\n",
      "Epoch 48/100\n",
      "461/461 [==============================] - 0s 294us/step - loss: 0.4840 - accuracy: 0.7722\n",
      "Epoch 49/100\n",
      "461/461 [==============================] - 0s 318us/step - loss: 0.4501 - accuracy: 0.7636\n",
      "Epoch 50/100\n",
      "461/461 [==============================] - 0s 303us/step - loss: 0.4779 - accuracy: 0.7614\n",
      "Epoch 51/100\n",
      "461/461 [==============================] - 0s 322us/step - loss: 0.4836 - accuracy: 0.7701\n",
      "Epoch 52/100\n",
      "461/461 [==============================] - 0s 303us/step - loss: 0.4453 - accuracy: 0.7679\n",
      "Epoch 53/100\n",
      "461/461 [==============================] - 0s 316us/step - loss: 0.4931 - accuracy: 0.7831\n",
      "Epoch 54/100\n",
      "461/461 [==============================] - 0s 307us/step - loss: 0.4826 - accuracy: 0.7636\n",
      "Epoch 55/100\n",
      "461/461 [==============================] - 0s 299us/step - loss: 0.4793 - accuracy: 0.7375\n",
      "Epoch 56/100\n",
      "461/461 [==============================] - 0s 312us/step - loss: 0.4786 - accuracy: 0.7679\n",
      "Epoch 57/100\n",
      "461/461 [==============================] - 0s 312us/step - loss: 0.4868 - accuracy: 0.7701\n",
      "Epoch 58/100\n",
      "461/461 [==============================] - 0s 303us/step - loss: 0.4816 - accuracy: 0.7787\n",
      "Epoch 59/100\n",
      "461/461 [==============================] - 0s 301us/step - loss: 0.4808 - accuracy: 0.7549\n",
      "Epoch 60/100\n",
      "461/461 [==============================] - 0s 301us/step - loss: 0.4742 - accuracy: 0.7766\n",
      "Epoch 61/100\n",
      "461/461 [==============================] - 0s 320us/step - loss: 0.4579 - accuracy: 0.8069\n",
      "Epoch 62/100\n",
      "461/461 [==============================] - 0s 292us/step - loss: 0.4703 - accuracy: 0.7570\n",
      "Epoch 63/100\n",
      "461/461 [==============================] - 0s 320us/step - loss: 0.4565 - accuracy: 0.7614\n",
      "Epoch 64/100\n",
      "461/461 [==============================] - 0s 322us/step - loss: 0.4655 - accuracy: 0.7874\n",
      "Epoch 65/100\n",
      "461/461 [==============================] - 0s 322us/step - loss: 0.4801 - accuracy: 0.7744\n",
      "Epoch 66/100\n",
      "461/461 [==============================] - 0s 292us/step - loss: 0.4713 - accuracy: 0.7679\n",
      "Epoch 67/100\n",
      "461/461 [==============================] - 0s 322us/step - loss: 0.4682 - accuracy: 0.7787\n",
      "Epoch 68/100\n",
      "461/461 [==============================] - 0s 294us/step - loss: 0.4654 - accuracy: 0.7896\n",
      "Epoch 69/100\n",
      "461/461 [==============================] - 0s 340us/step - loss: 0.4643 - accuracy: 0.7787\n",
      "Epoch 70/100\n",
      "461/461 [==============================] - 0s 301us/step - loss: 0.4616 - accuracy: 0.7787\n",
      "Epoch 71/100\n",
      "461/461 [==============================] - 0s 309us/step - loss: 0.4419 - accuracy: 0.7852\n",
      "Epoch 72/100\n",
      "461/461 [==============================] - 0s 316us/step - loss: 0.4608 - accuracy: 0.8069\n",
      "Epoch 73/100\n",
      "461/461 [==============================] - 0s 314us/step - loss: 0.4598 - accuracy: 0.7701\n",
      "Epoch 74/100\n",
      "461/461 [==============================] - 0s 318us/step - loss: 0.4607 - accuracy: 0.7701\n",
      "Epoch 75/100\n",
      "461/461 [==============================] - 0s 303us/step - loss: 0.4727 - accuracy: 0.7505\n",
      "Epoch 76/100\n",
      "461/461 [==============================] - 0s 335us/step - loss: 0.4569 - accuracy: 0.7701\n",
      "Epoch 77/100\n",
      "461/461 [==============================] - 0s 322us/step - loss: 0.4475 - accuracy: 0.7744\n",
      "Epoch 78/100\n",
      "461/461 [==============================] - 0s 379us/step - loss: 0.4743 - accuracy: 0.7375\n",
      "Epoch 79/100\n",
      "461/461 [==============================] - 0s 366us/step - loss: 0.4868 - accuracy: 0.7527\n",
      "Epoch 80/100\n",
      "461/461 [==============================] - 0s 327us/step - loss: 0.4596 - accuracy: 0.7592\n",
      "Epoch 81/100\n",
      "461/461 [==============================] - 0s 359us/step - loss: 0.4626 - accuracy: 0.7614\n",
      "Epoch 82/100\n",
      "461/461 [==============================] - 0s 389us/step - loss: 0.4369 - accuracy: 0.8026\n",
      "Epoch 83/100\n",
      "461/461 [==============================] - 0s 374us/step - loss: 0.4508 - accuracy: 0.7787\n",
      "Epoch 84/100\n",
      "461/461 [==============================] - 0s 389us/step - loss: 0.4684 - accuracy: 0.7657\n",
      "Epoch 85/100\n",
      "461/461 [==============================] - 0s 405us/step - loss: 0.4413 - accuracy: 0.7831\n",
      "Epoch 86/100\n",
      "461/461 [==============================] - 0s 385us/step - loss: 0.4603 - accuracy: 0.7831\n",
      "Epoch 87/100\n",
      "461/461 [==============================] - 0s 389us/step - loss: 0.4642 - accuracy: 0.7527\n",
      "Epoch 88/100\n",
      "461/461 [==============================] - 0s 340us/step - loss: 0.4518 - accuracy: 0.7766\n",
      "Epoch 89/100\n",
      "461/461 [==============================] - 0s 348us/step - loss: 0.4792 - accuracy: 0.7440\n",
      "Epoch 90/100\n",
      "461/461 [==============================] - 0s 363us/step - loss: 0.4710 - accuracy: 0.7375\n",
      "Epoch 91/100\n",
      "461/461 [==============================] - 0s 316us/step - loss: 0.4605 - accuracy: 0.7939\n",
      "Epoch 92/100\n",
      "461/461 [==============================] - 0s 307us/step - loss: 0.4657 - accuracy: 0.7744\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461/461 [==============================] - 0s 312us/step - loss: 0.4682 - accuracy: 0.7722\n",
      "Epoch 94/100\n",
      "461/461 [==============================] - 0s 292us/step - loss: 0.4587 - accuracy: 0.7831\n",
      "Epoch 95/100\n",
      "461/461 [==============================] - 0s 303us/step - loss: 0.4651 - accuracy: 0.7657\n",
      "Epoch 96/100\n",
      "461/461 [==============================] - 0s 312us/step - loss: 0.4571 - accuracy: 0.7766\n",
      "Epoch 97/100\n",
      "461/461 [==============================] - 0s 299us/step - loss: 0.4440 - accuracy: 0.7939\n",
      "Epoch 98/100\n",
      "461/461 [==============================] - 0s 325us/step - loss: 0.4292 - accuracy: 0.7701\n",
      "Epoch 99/100\n",
      "461/461 [==============================] - 0s 296us/step - loss: 0.4634 - accuracy: 0.7766\n",
      "Epoch 100/100\n",
      "461/461 [==============================] - 0s 303us/step - loss: 0.4715 - accuracy: 0.7505\n",
      "Epoch 1/100\n",
      "461/461 [==============================] - 0s 1ms/step - loss: 0.6592 - accuracy: 0.6551\n",
      "Epoch 2/100\n",
      "461/461 [==============================] - 0s 168us/step - loss: 0.6229 - accuracy: 0.6464\n",
      "Epoch 3/100\n",
      "461/461 [==============================] - 0s 178us/step - loss: 0.5664 - accuracy: 0.6920\n",
      "Epoch 4/100\n",
      "461/461 [==============================] - 0s 169us/step - loss: 0.5431 - accuracy: 0.7202\n",
      "Epoch 5/100\n",
      "461/461 [==============================] - 0s 169us/step - loss: 0.5259 - accuracy: 0.7440\n",
      "Epoch 6/100\n",
      "461/461 [==============================] - 0s 167us/step - loss: 0.5290 - accuracy: 0.7267\n",
      "Epoch 7/100\n",
      "461/461 [==============================] - 0s 164us/step - loss: 0.5362 - accuracy: 0.7267\n",
      "Epoch 8/100\n",
      "461/461 [==============================] - 0s 304us/step - loss: 0.5293 - accuracy: 0.7245\n",
      "Epoch 9/100\n",
      "461/461 [==============================] - 0s 322us/step - loss: 0.5161 - accuracy: 0.7375\n",
      "Epoch 10/100\n",
      "461/461 [==============================] - 0s 320us/step - loss: 0.5400 - accuracy: 0.7050\n",
      "Epoch 11/100\n",
      "461/461 [==============================] - 0s 290us/step - loss: 0.4887 - accuracy: 0.7419\n",
      "Epoch 12/100\n",
      "461/461 [==============================] - 0s 312us/step - loss: 0.5211 - accuracy: 0.7462\n",
      "Epoch 13/100\n",
      "461/461 [==============================] - 0s 307us/step - loss: 0.4929 - accuracy: 0.7375\n",
      "Epoch 14/100\n",
      "461/461 [==============================] - 0s 305us/step - loss: 0.4926 - accuracy: 0.7614\n",
      "Epoch 15/100\n",
      "461/461 [==============================] - 0s 309us/step - loss: 0.4977 - accuracy: 0.7462\n",
      "Epoch 16/100\n",
      "461/461 [==============================] - 0s 309us/step - loss: 0.5144 - accuracy: 0.7419\n",
      "Epoch 17/100\n",
      "461/461 [==============================] - 0s 318us/step - loss: 0.4886 - accuracy: 0.7592\n",
      "Epoch 18/100\n",
      "461/461 [==============================] - 0s 316us/step - loss: 0.5001 - accuracy: 0.7462\n",
      "Epoch 19/100\n",
      "461/461 [==============================] - 0s 314us/step - loss: 0.4713 - accuracy: 0.7592\n",
      "Epoch 20/100\n",
      "461/461 [==============================] - 0s 303us/step - loss: 0.4856 - accuracy: 0.7679\n",
      "Epoch 21/100\n",
      "461/461 [==============================] - 0s 307us/step - loss: 0.4732 - accuracy: 0.7549\n",
      "Epoch 22/100\n",
      "461/461 [==============================] - 0s 333us/step - loss: 0.4754 - accuracy: 0.7570\n",
      "Epoch 23/100\n",
      "461/461 [==============================] - 0s 307us/step - loss: 0.4900 - accuracy: 0.7505\n",
      "Epoch 24/100\n",
      "461/461 [==============================] - 0s 383us/step - loss: 0.4784 - accuracy: 0.7701\n",
      "Epoch 25/100\n",
      "461/461 [==============================] - 0s 303us/step - loss: 0.4932 - accuracy: 0.7527\n",
      "Epoch 26/100\n",
      "461/461 [==============================] - 0s 331us/step - loss: 0.4730 - accuracy: 0.7809\n",
      "Epoch 27/100\n",
      "461/461 [==============================] - 0s 307us/step - loss: 0.4831 - accuracy: 0.7592\n",
      "Epoch 28/100\n",
      "461/461 [==============================] - 0s 327us/step - loss: 0.4942 - accuracy: 0.7462\n",
      "Epoch 29/100\n",
      "461/461 [==============================] - 0s 305us/step - loss: 0.4575 - accuracy: 0.7787\n",
      "Epoch 30/100\n",
      "461/461 [==============================] - 0s 329us/step - loss: 0.4807 - accuracy: 0.7527\n",
      "Epoch 31/100\n",
      "461/461 [==============================] - 0s 309us/step - loss: 0.4791 - accuracy: 0.7397\n",
      "Epoch 32/100\n",
      "461/461 [==============================] - 0s 307us/step - loss: 0.4670 - accuracy: 0.7722\n",
      "Epoch 33/100\n",
      "461/461 [==============================] - 0s 387us/step - loss: 0.4728 - accuracy: 0.7440\n",
      "Epoch 34/100\n",
      "461/461 [==============================] - 0s 366us/step - loss: 0.4794 - accuracy: 0.7527\n",
      "Epoch 35/100\n",
      "461/461 [==============================] - 0s 314us/step - loss: 0.4636 - accuracy: 0.7636\n",
      "Epoch 36/100\n",
      "461/461 [==============================] - 0s 312us/step - loss: 0.4582 - accuracy: 0.7766\n",
      "Epoch 37/100\n",
      "461/461 [==============================] - 0s 337us/step - loss: 0.4676 - accuracy: 0.7549\n",
      "Epoch 38/100\n",
      "461/461 [==============================] - 0s 366us/step - loss: 0.4983 - accuracy: 0.7419\n",
      "Epoch 39/100\n",
      "461/461 [==============================] - 0s 329us/step - loss: 0.4623 - accuracy: 0.7636\n",
      "Epoch 40/100\n",
      "461/461 [==============================] - 0s 303us/step - loss: 0.4641 - accuracy: 0.7614\n",
      "Epoch 41/100\n",
      "461/461 [==============================] - 0s 320us/step - loss: 0.4841 - accuracy: 0.7657\n",
      "Epoch 42/100\n",
      "461/461 [==============================] - 0s 309us/step - loss: 0.4382 - accuracy: 0.8004\n",
      "Epoch 43/100\n",
      "461/461 [==============================] - 0s 387us/step - loss: 0.4774 - accuracy: 0.7657\n",
      "Epoch 44/100\n",
      "461/461 [==============================] - 0s 359us/step - loss: 0.4729 - accuracy: 0.7657\n",
      "Epoch 45/100\n",
      "461/461 [==============================] - 0s 301us/step - loss: 0.4651 - accuracy: 0.7570\n",
      "Epoch 46/100\n",
      "461/461 [==============================] - 0s 312us/step - loss: 0.4351 - accuracy: 0.7831\n",
      "Epoch 47/100\n",
      "461/461 [==============================] - 0s 309us/step - loss: 0.4536 - accuracy: 0.7831\n",
      "Epoch 48/100\n",
      "461/461 [==============================] - 0s 322us/step - loss: 0.4922 - accuracy: 0.7592\n",
      "Epoch 49/100\n",
      "461/461 [==============================] - 0s 314us/step - loss: 0.4631 - accuracy: 0.7787\n",
      "Epoch 50/100\n",
      "461/461 [==============================] - 0s 307us/step - loss: 0.4690 - accuracy: 0.7484\n",
      "Epoch 51/100\n",
      "461/461 [==============================] - 0s 333us/step - loss: 0.4475 - accuracy: 0.7918\n",
      "Epoch 52/100\n",
      "461/461 [==============================] - 0s 294us/step - loss: 0.4751 - accuracy: 0.7657\n",
      "Epoch 53/100\n",
      "461/461 [==============================] - 0s 335us/step - loss: 0.5024 - accuracy: 0.7419\n",
      "Epoch 54/100\n",
      "461/461 [==============================] - 0s 301us/step - loss: 0.4583 - accuracy: 0.7657\n",
      "Epoch 55/100\n",
      "461/461 [==============================] - 0s 325us/step - loss: 0.4736 - accuracy: 0.7570\n",
      "Epoch 56/100\n",
      "461/461 [==============================] - 0s 299us/step - loss: 0.4812 - accuracy: 0.7527\n",
      "Epoch 57/100\n",
      "461/461 [==============================] - 0s 325us/step - loss: 0.4833 - accuracy: 0.7614\n",
      "Epoch 58/100\n",
      "461/461 [==============================] - 0s 307us/step - loss: 0.4649 - accuracy: 0.7722\n",
      "Epoch 59/100\n",
      "461/461 [==============================] - 0s 322us/step - loss: 0.4736 - accuracy: 0.7787\n",
      "Epoch 60/100\n",
      "461/461 [==============================] - 0s 301us/step - loss: 0.4667 - accuracy: 0.7462\n",
      "Epoch 61/100\n",
      "461/461 [==============================] - 0s 327us/step - loss: 0.4812 - accuracy: 0.7505\n",
      "Epoch 62/100\n",
      "461/461 [==============================] - 0s 331us/step - loss: 0.4654 - accuracy: 0.7549\n",
      "Epoch 63/100\n",
      "461/461 [==============================] - 0s 314us/step - loss: 0.4410 - accuracy: 0.7787\n",
      "Epoch 64/100\n",
      "461/461 [==============================] - 0s 337us/step - loss: 0.4580 - accuracy: 0.7592\n",
      "Epoch 65/100\n",
      "461/461 [==============================] - 0s 299us/step - loss: 0.4700 - accuracy: 0.7722\n",
      "Epoch 66/100\n",
      "461/461 [==============================] - 0s 327us/step - loss: 0.4454 - accuracy: 0.7787\n",
      "Epoch 67/100\n",
      "461/461 [==============================] - 0s 296us/step - loss: 0.4643 - accuracy: 0.7744\n",
      "Epoch 68/100\n",
      "461/461 [==============================] - 0s 333us/step - loss: 0.4357 - accuracy: 0.7809\n",
      "Epoch 69/100\n",
      "461/461 [==============================] - 0s 303us/step - loss: 0.4405 - accuracy: 0.8004\n",
      "Epoch 70/100\n",
      "461/461 [==============================] - 0s 316us/step - loss: 0.4469 - accuracy: 0.7939\n",
      "Epoch 71/100\n",
      "461/461 [==============================] - 0s 312us/step - loss: 0.4346 - accuracy: 0.7918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "461/461 [==============================] - 0s 322us/step - loss: 0.4663 - accuracy: 0.7744\n",
      "Epoch 73/100\n",
      "461/461 [==============================] - 0s 383us/step - loss: 0.4558 - accuracy: 0.7787\n",
      "Epoch 74/100\n",
      "461/461 [==============================] - 0s 314us/step - loss: 0.4668 - accuracy: 0.7527\n",
      "Epoch 75/100\n",
      "461/461 [==============================] - 0s 290us/step - loss: 0.4575 - accuracy: 0.7939\n",
      "Epoch 76/100\n",
      "461/461 [==============================] - 0s 331us/step - loss: 0.4411 - accuracy: 0.7939\n",
      "Epoch 77/100\n",
      "461/461 [==============================] - 0s 301us/step - loss: 0.4527 - accuracy: 0.7809\n",
      "Epoch 78/100\n",
      "461/461 [==============================] - 0s 413us/step - loss: 0.4520 - accuracy: 0.7874\n",
      "Epoch 79/100\n",
      "461/461 [==============================] - 0s 307us/step - loss: 0.4530 - accuracy: 0.8004\n",
      "Epoch 80/100\n",
      "461/461 [==============================] - 0s 372us/step - loss: 0.4321 - accuracy: 0.7744\n",
      "Epoch 81/100\n",
      "461/461 [==============================] - 0s 368us/step - loss: 0.4581 - accuracy: 0.7809\n",
      "Epoch 82/100\n",
      "461/461 [==============================] - 0s 372us/step - loss: 0.4628 - accuracy: 0.8026\n",
      "Epoch 83/100\n",
      "461/461 [==============================] - 0s 372us/step - loss: 0.4418 - accuracy: 0.7831\n",
      "Epoch 84/100\n",
      "461/461 [==============================] - 0s 385us/step - loss: 0.4524 - accuracy: 0.7983\n",
      "Epoch 85/100\n",
      "461/461 [==============================] - 0s 394us/step - loss: 0.4556 - accuracy: 0.7896\n",
      "Epoch 86/100\n",
      "461/461 [==============================] - 0s 389us/step - loss: 0.4332 - accuracy: 0.7896\n",
      "Epoch 87/100\n",
      "461/461 [==============================] - 0s 383us/step - loss: 0.4535 - accuracy: 0.7809\n",
      "Epoch 88/100\n",
      "461/461 [==============================] - 0s 374us/step - loss: 0.4430 - accuracy: 0.7918\n",
      "Epoch 89/100\n",
      "461/461 [==============================] - 0s 383us/step - loss: 0.4648 - accuracy: 0.7831\n",
      "Epoch 90/100\n",
      "461/461 [==============================] - 0s 379us/step - loss: 0.4574 - accuracy: 0.7961\n",
      "Epoch 91/100\n",
      "461/461 [==============================] - 0s 383us/step - loss: 0.4286 - accuracy: 0.7939\n",
      "Epoch 92/100\n",
      "461/461 [==============================] - 0s 342us/step - loss: 0.4465 - accuracy: 0.77010s - loss: 0.4716 - accuracy: 0.\n",
      "Epoch 93/100\n",
      "461/461 [==============================] - 0s 346us/step - loss: 0.4665 - accuracy: 0.7852\n",
      "Epoch 94/100\n",
      "461/461 [==============================] - 0s 305us/step - loss: 0.4353 - accuracy: 0.8026\n",
      "Epoch 95/100\n",
      "461/461 [==============================] - 0s 307us/step - loss: 0.4572 - accuracy: 0.7787\n",
      "Epoch 96/100\n",
      "461/461 [==============================] - 0s 305us/step - loss: 0.4118 - accuracy: 0.8351\n",
      "Epoch 97/100\n",
      "461/461 [==============================] - 0s 299us/step - loss: 0.4330 - accuracy: 0.7939\n",
      "Epoch 98/100\n",
      "461/461 [==============================] - 0s 320us/step - loss: 0.4503 - accuracy: 0.8004\n",
      "Epoch 99/100\n",
      "461/461 [==============================] - 0s 294us/step - loss: 0.4338 - accuracy: 0.7961\n",
      "Epoch 100/100\n",
      "461/461 [==============================] - 0s 312us/step - loss: 0.4267 - accuracy: 0.8048\n",
      "Epoch 1/300\n",
      "460/460 [==============================] - 1s 2ms/step - loss: 0.7640 - accuracy: 0.5457\n",
      "Epoch 2/300\n",
      "460/460 [==============================] - 0s 325us/step - loss: 0.6656 - accuracy: 0.6283\n",
      "Epoch 3/300\n",
      "460/460 [==============================] - 0s 310us/step - loss: 0.6375 - accuracy: 0.6804\n",
      "Epoch 4/300\n",
      "460/460 [==============================] - 0s 252us/step - loss: 0.6184 - accuracy: 0.6783\n",
      "Epoch 5/300\n",
      "460/460 [==============================] - 0s 167us/step - loss: 0.5929 - accuracy: 0.7217\n",
      "Epoch 6/300\n",
      "460/460 [==============================] - 0s 182us/step - loss: 0.5766 - accuracy: 0.7261\n",
      "Epoch 7/300\n",
      "460/460 [==============================] - 0s 182us/step - loss: 0.5817 - accuracy: 0.7217\n",
      "Epoch 8/300\n",
      "460/460 [==============================] - 0s 173us/step - loss: 0.5454 - accuracy: 0.7348\n",
      "Epoch 9/300\n",
      "460/460 [==============================] - 0s 169us/step - loss: 0.5391 - accuracy: 0.7196\n",
      "Epoch 10/300\n",
      "460/460 [==============================] - 0s 169us/step - loss: 0.5298 - accuracy: 0.7652\n",
      "Epoch 11/300\n",
      "460/460 [==============================] - 0s 176us/step - loss: 0.5484 - accuracy: 0.7326\n",
      "Epoch 12/300\n",
      "460/460 [==============================] - 0s 171us/step - loss: 0.5235 - accuracy: 0.7391\n",
      "Epoch 13/300\n",
      "460/460 [==============================] - 0s 167us/step - loss: 0.5261 - accuracy: 0.7261\n",
      "Epoch 14/300\n",
      "460/460 [==============================] - 0s 182us/step - loss: 0.5258 - accuracy: 0.7304\n",
      "Epoch 15/300\n",
      "460/460 [==============================] - 0s 176us/step - loss: 0.5211 - accuracy: 0.7348\n",
      "Epoch 16/300\n",
      "460/460 [==============================] - 0s 272us/step - loss: 0.5144 - accuracy: 0.7522\n",
      "Epoch 17/300\n",
      "460/460 [==============================] - 0s 332us/step - loss: 0.5133 - accuracy: 0.7522\n",
      "Epoch 18/300\n",
      "460/460 [==============================] - 0s 312us/step - loss: 0.4851 - accuracy: 0.7804\n",
      "Epoch 19/300\n",
      "460/460 [==============================] - 0s 327us/step - loss: 0.5149 - accuracy: 0.7587\n",
      "Epoch 20/300\n",
      "460/460 [==============================] - 0s 310us/step - loss: 0.5324 - accuracy: 0.7370\n",
      "Epoch 21/300\n",
      "460/460 [==============================] - 0s 308us/step - loss: 0.5114 - accuracy: 0.7435\n",
      "Epoch 22/300\n",
      "460/460 [==============================] - 0s 321us/step - loss: 0.5036 - accuracy: 0.7457\n",
      "Epoch 23/300\n",
      "460/460 [==============================] - 0s 314us/step - loss: 0.4905 - accuracy: 0.7543\n",
      "Epoch 24/300\n",
      "460/460 [==============================] - 0s 338us/step - loss: 0.4828 - accuracy: 0.7739\n",
      "Epoch 25/300\n",
      "460/460 [==============================] - 0s 312us/step - loss: 0.4971 - accuracy: 0.7435\n",
      "Epoch 26/300\n",
      "460/460 [==============================] - 0s 319us/step - loss: 0.5001 - accuracy: 0.7565\n",
      "Epoch 27/300\n",
      "460/460 [==============================] - 0s 334us/step - loss: 0.4920 - accuracy: 0.7435\n",
      "Epoch 28/300\n",
      "460/460 [==============================] - 0s 310us/step - loss: 0.4995 - accuracy: 0.7696\n",
      "Epoch 29/300\n",
      "460/460 [==============================] - 0s 306us/step - loss: 0.5286 - accuracy: 0.7261\n",
      "Epoch 30/300\n",
      "460/460 [==============================] - 0s 327us/step - loss: 0.4899 - accuracy: 0.7652\n",
      "Epoch 31/300\n",
      "460/460 [==============================] - 0s 358us/step - loss: 0.5026 - accuracy: 0.7478\n",
      "Epoch 32/300\n",
      "460/460 [==============================] - 0s 314us/step - loss: 0.4780 - accuracy: 0.7522\n",
      "Epoch 33/300\n",
      "460/460 [==============================] - 0s 312us/step - loss: 0.4789 - accuracy: 0.7609\n",
      "Epoch 34/300\n",
      "460/460 [==============================] - 0s 319us/step - loss: 0.5035 - accuracy: 0.7304\n",
      "Epoch 35/300\n",
      "460/460 [==============================] - 0s 356us/step - loss: 0.5061 - accuracy: 0.7674\n",
      "Epoch 36/300\n",
      "460/460 [==============================] - 0s 310us/step - loss: 0.4729 - accuracy: 0.7804\n",
      "Epoch 37/300\n",
      "460/460 [==============================] - 0s 327us/step - loss: 0.4858 - accuracy: 0.7543\n",
      "Epoch 38/300\n",
      "460/460 [==============================] - 0s 304us/step - loss: 0.5123 - accuracy: 0.7391\n",
      "Epoch 39/300\n",
      "460/460 [==============================] - 0s 343us/step - loss: 0.5056 - accuracy: 0.7565\n",
      "Epoch 40/300\n",
      "460/460 [==============================] - 0s 297us/step - loss: 0.4697 - accuracy: 0.7674\n",
      "Epoch 41/300\n",
      "460/460 [==============================] - 0s 319us/step - loss: 0.4836 - accuracy: 0.7717\n",
      "Epoch 42/300\n",
      "460/460 [==============================] - 0s 330us/step - loss: 0.4880 - accuracy: 0.7609\n",
      "Epoch 43/300\n",
      "460/460 [==============================] - 0s 360us/step - loss: 0.5027 - accuracy: 0.7391\n",
      "Epoch 44/300\n",
      "460/460 [==============================] - 0s 379us/step - loss: 0.5281 - accuracy: 0.7370\n",
      "Epoch 45/300\n",
      "460/460 [==============================] - 0s 321us/step - loss: 0.5015 - accuracy: 0.7543\n",
      "Epoch 46/300\n",
      "460/460 [==============================] - 0s 327us/step - loss: 0.4794 - accuracy: 0.7652\n",
      "Epoch 47/300\n",
      "460/460 [==============================] - 0s 340us/step - loss: 0.5012 - accuracy: 0.7609\n",
      "Epoch 48/300\n",
      "460/460 [==============================] - 0s 314us/step - loss: 0.5032 - accuracy: 0.7370\n",
      "Epoch 49/300\n",
      "460/460 [==============================] - 0s 319us/step - loss: 0.4925 - accuracy: 0.7674\n",
      "Epoch 50/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460/460 [==============================] - 0s 321us/step - loss: 0.4681 - accuracy: 0.7565\n",
      "Epoch 51/300\n",
      "460/460 [==============================] - 0s 325us/step - loss: 0.4865 - accuracy: 0.7783\n",
      "Epoch 52/300\n",
      "460/460 [==============================] - 0s 295us/step - loss: 0.4994 - accuracy: 0.7652\n",
      "Epoch 53/300\n",
      "460/460 [==============================] - 0s 306us/step - loss: 0.5094 - accuracy: 0.7630\n",
      "Epoch 54/300\n",
      "460/460 [==============================] - 0s 308us/step - loss: 0.4975 - accuracy: 0.7543\n",
      "Epoch 55/300\n",
      "460/460 [==============================] - 0s 321us/step - loss: 0.4955 - accuracy: 0.7630\n",
      "Epoch 56/300\n",
      "460/460 [==============================] - 0s 317us/step - loss: 0.4874 - accuracy: 0.7674\n",
      "Epoch 57/300\n",
      "460/460 [==============================] - 0s 308us/step - loss: 0.5060 - accuracy: 0.7761\n",
      "Epoch 58/300\n",
      "460/460 [==============================] - 0s 332us/step - loss: 0.5207 - accuracy: 0.7478\n",
      "Epoch 59/300\n",
      "460/460 [==============================] - 0s 304us/step - loss: 0.4939 - accuracy: 0.7674\n",
      "Epoch 60/300\n",
      "460/460 [==============================] - 0s 308us/step - loss: 0.4786 - accuracy: 0.7652\n",
      "Epoch 61/300\n",
      "460/460 [==============================] - 0s 369us/step - loss: 0.4963 - accuracy: 0.7457\n",
      "Epoch 62/300\n",
      "460/460 [==============================] - 0s 282us/step - loss: 0.4812 - accuracy: 0.7652\n",
      "Epoch 63/300\n",
      "460/460 [==============================] - 0s 243us/step - loss: 0.4776 - accuracy: 0.7804\n",
      "Epoch 64/300\n",
      "460/460 [==============================] - 0s 206us/step - loss: 0.4986 - accuracy: 0.7500\n",
      "Epoch 65/300\n",
      "460/460 [==============================] - 0s 223us/step - loss: 0.4946 - accuracy: 0.7478\n",
      "Epoch 66/300\n",
      "460/460 [==============================] - 0s 225us/step - loss: 0.4917 - accuracy: 0.7565\n",
      "Epoch 67/300\n",
      "460/460 [==============================] - 0s 212us/step - loss: 0.4924 - accuracy: 0.7565\n",
      "Epoch 68/300\n",
      "460/460 [==============================] - 0s 236us/step - loss: 0.4732 - accuracy: 0.7543\n",
      "Epoch 69/300\n",
      "460/460 [==============================] - 0s 223us/step - loss: 0.4879 - accuracy: 0.7587\n",
      "Epoch 70/300\n",
      "460/460 [==============================] - 0s 238us/step - loss: 0.4779 - accuracy: 0.7826\n",
      "Epoch 71/300\n",
      "460/460 [==============================] - 0s 293us/step - loss: 0.4829 - accuracy: 0.7457\n",
      "Epoch 72/300\n",
      "460/460 [==============================] - 0s 399us/step - loss: 0.5013 - accuracy: 0.7630\n",
      "Epoch 73/300\n",
      "460/460 [==============================] - 0s 332us/step - loss: 0.4781 - accuracy: 0.7630\n",
      "Epoch 74/300\n",
      "460/460 [==============================] - 0s 301us/step - loss: 0.4831 - accuracy: 0.7500\n",
      "Epoch 75/300\n",
      "460/460 [==============================] - 0s 319us/step - loss: 0.5029 - accuracy: 0.7478\n",
      "Epoch 76/300\n",
      "460/460 [==============================] - 0s 310us/step - loss: 0.4781 - accuracy: 0.7587\n",
      "Epoch 77/300\n",
      "460/460 [==============================] - 0s 332us/step - loss: 0.4776 - accuracy: 0.7652\n",
      "Epoch 78/300\n",
      "460/460 [==============================] - 0s 299us/step - loss: 0.4966 - accuracy: 0.7478\n",
      "Epoch 79/300\n",
      "460/460 [==============================] - 0s 317us/step - loss: 0.4901 - accuracy: 0.7609\n",
      "Epoch 80/300\n",
      "460/460 [==============================] - 0s 308us/step - loss: 0.4771 - accuracy: 0.7652\n",
      "Epoch 81/300\n",
      "460/460 [==============================] - 0s 327us/step - loss: 0.4765 - accuracy: 0.7717\n",
      "Epoch 82/300\n",
      "460/460 [==============================] - 0s 306us/step - loss: 0.4861 - accuracy: 0.7478\n",
      "Epoch 83/300\n",
      "460/460 [==============================] - 0s 334us/step - loss: 0.4869 - accuracy: 0.7435\n",
      "Epoch 84/300\n",
      "460/460 [==============================] - 0s 319us/step - loss: 0.4678 - accuracy: 0.7717\n",
      "Epoch 85/300\n",
      "460/460 [==============================] - 0s 332us/step - loss: 0.4816 - accuracy: 0.7717\n",
      "Epoch 86/300\n",
      "460/460 [==============================] - 0s 319us/step - loss: 0.4805 - accuracy: 0.7652\n",
      "Epoch 87/300\n",
      "460/460 [==============================] - 0s 310us/step - loss: 0.4682 - accuracy: 0.7522\n",
      "Epoch 88/300\n",
      "460/460 [==============================] - 0s 336us/step - loss: 0.4562 - accuracy: 0.7652\n",
      "Epoch 89/300\n",
      "460/460 [==============================] - 0s 297us/step - loss: 0.5209 - accuracy: 0.7522\n",
      "Epoch 90/300\n",
      "460/460 [==============================] - 0s 325us/step - loss: 0.4797 - accuracy: 0.7630\n",
      "Epoch 91/300\n",
      "460/460 [==============================] - 0s 308us/step - loss: 0.4740 - accuracy: 0.7543\n",
      "Epoch 92/300\n",
      "460/460 [==============================] - 0s 327us/step - loss: 0.4833 - accuracy: 0.7565\n",
      "Epoch 93/300\n",
      "460/460 [==============================] - 0s 340us/step - loss: 0.4966 - accuracy: 0.7370\n",
      "Epoch 94/300\n",
      "460/460 [==============================] - 0s 306us/step - loss: 0.4595 - accuracy: 0.7783\n",
      "Epoch 95/300\n",
      "460/460 [==============================] - 0s 308us/step - loss: 0.4706 - accuracy: 0.7783\n",
      "Epoch 96/300\n",
      "460/460 [==============================] - 0s 330us/step - loss: 0.5003 - accuracy: 0.7717\n",
      "Epoch 97/300\n",
      "460/460 [==============================] - 0s 306us/step - loss: 0.4706 - accuracy: 0.7587\n",
      "Epoch 98/300\n",
      "460/460 [==============================] - 0s 330us/step - loss: 0.4720 - accuracy: 0.7565\n",
      "Epoch 99/300\n",
      "460/460 [==============================] - 0s 295us/step - loss: 0.4720 - accuracy: 0.7717\n",
      "Epoch 100/300\n",
      "460/460 [==============================] - 0s 330us/step - loss: 0.4713 - accuracy: 0.7609\n",
      "Epoch 101/300\n",
      "460/460 [==============================] - 0s 360us/step - loss: 0.4670 - accuracy: 0.7717\n",
      "Epoch 102/300\n",
      "460/460 [==============================] - 0s 312us/step - loss: 0.4685 - accuracy: 0.7717\n",
      "Epoch 103/300\n",
      "460/460 [==============================] - 0s 334us/step - loss: 0.5031 - accuracy: 0.7391\n",
      "Epoch 104/300\n",
      "460/460 [==============================] - 0s 325us/step - loss: 0.5027 - accuracy: 0.7522\n",
      "Epoch 105/300\n",
      "460/460 [==============================] - 0s 306us/step - loss: 0.4523 - accuracy: 0.7761\n",
      "Epoch 106/300\n",
      "460/460 [==============================] - 0s 308us/step - loss: 0.4879 - accuracy: 0.7543\n",
      "Epoch 107/300\n",
      "460/460 [==============================] - 0s 317us/step - loss: 0.4728 - accuracy: 0.7761\n",
      "Epoch 108/300\n",
      "460/460 [==============================] - 0s 384us/step - loss: 0.4916 - accuracy: 0.7457\n",
      "Epoch 109/300\n",
      "460/460 [==============================] - 0s 392us/step - loss: 0.4813 - accuracy: 0.7674\n",
      "Epoch 110/300\n",
      "460/460 [==============================] - 0s 330us/step - loss: 0.4808 - accuracy: 0.7500\n",
      "Epoch 111/300\n",
      "460/460 [==============================] - 0s 343us/step - loss: 0.4603 - accuracy: 0.7457\n",
      "Epoch 112/300\n",
      "460/460 [==============================] - 0s 304us/step - loss: 0.4336 - accuracy: 0.7935\n",
      "Epoch 113/300\n",
      "460/460 [==============================] - 0s 319us/step - loss: 0.4887 - accuracy: 0.7522\n",
      "Epoch 114/300\n",
      "460/460 [==============================] - 0s 304us/step - loss: 0.4792 - accuracy: 0.7696\n",
      "Epoch 115/300\n",
      "460/460 [==============================] - 0s 330us/step - loss: 0.4582 - accuracy: 0.7674\n",
      "Epoch 116/300\n",
      "460/460 [==============================] - 0s 304us/step - loss: 0.4828 - accuracy: 0.7304\n",
      "Epoch 117/300\n",
      "460/460 [==============================] - 0s 323us/step - loss: 0.4679 - accuracy: 0.7652\n",
      "Epoch 118/300\n",
      "460/460 [==============================] - 0s 301us/step - loss: 0.4772 - accuracy: 0.7848\n",
      "Epoch 119/300\n",
      "460/460 [==============================] - 0s 332us/step - loss: 0.4680 - accuracy: 0.7630\n",
      "Epoch 120/300\n",
      "460/460 [==============================] - 0s 304us/step - loss: 0.4782 - accuracy: 0.7674\n",
      "Epoch 121/300\n",
      "460/460 [==============================] - 0s 310us/step - loss: 0.4796 - accuracy: 0.7674\n",
      "Epoch 122/300\n",
      "460/460 [==============================] - 0s 312us/step - loss: 0.4738 - accuracy: 0.7739\n",
      "Epoch 123/300\n",
      "460/460 [==============================] - 0s 349us/step - loss: 0.4797 - accuracy: 0.7478\n",
      "Epoch 124/300\n",
      "460/460 [==============================] - 0s 366us/step - loss: 0.4464 - accuracy: 0.7826\n",
      "Epoch 125/300\n",
      "460/460 [==============================] - 0s 319us/step - loss: 0.4538 - accuracy: 0.7891\n",
      "Epoch 126/300\n",
      "460/460 [==============================] - 0s 306us/step - loss: 0.4865 - accuracy: 0.7674\n",
      "Epoch 127/300\n",
      "460/460 [==============================] - 0s 308us/step - loss: 0.4757 - accuracy: 0.7696\n",
      "Epoch 128/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460/460 [==============================] - 0s 360us/step - loss: 0.4718 - accuracy: 0.7870\n",
      "Epoch 129/300\n",
      "460/460 [==============================] - 0s 304us/step - loss: 0.4597 - accuracy: 0.7913\n",
      "Epoch 130/300\n",
      "460/460 [==============================] - 0s 336us/step - loss: 0.4669 - accuracy: 0.7609\n",
      "Epoch 131/300\n",
      "460/460 [==============================] - 0s 317us/step - loss: 0.4773 - accuracy: 0.7609\n",
      "Epoch 132/300\n",
      "460/460 [==============================] - 0s 319us/step - loss: 0.4588 - accuracy: 0.7804\n",
      "Epoch 133/300\n",
      "460/460 [==============================] - 0s 304us/step - loss: 0.4906 - accuracy: 0.7609\n",
      "Epoch 134/300\n",
      "460/460 [==============================] - 0s 314us/step - loss: 0.4959 - accuracy: 0.7630\n",
      "Epoch 135/300\n",
      "460/460 [==============================] - 0s 330us/step - loss: 0.4924 - accuracy: 0.7500\n",
      "Epoch 136/300\n",
      "460/460 [==============================] - 0s 317us/step - loss: 0.4919 - accuracy: 0.7696\n",
      "Epoch 137/300\n",
      "460/460 [==============================] - 0s 187us/step - loss: 0.4776 - accuracy: 0.7565\n",
      "Epoch 138/300\n",
      "460/460 [==============================] - 0s 171us/step - loss: 0.4741 - accuracy: 0.7609\n",
      "Epoch 139/300\n",
      "460/460 [==============================] - 0s 167us/step - loss: 0.4669 - accuracy: 0.7717\n",
      "Epoch 140/300\n",
      "460/460 [==============================] - 0s 204us/step - loss: 0.5107 - accuracy: 0.7587\n",
      "Epoch 141/300\n",
      "460/460 [==============================] - 0s 189us/step - loss: 0.4914 - accuracy: 0.7543\n",
      "Epoch 142/300\n",
      "460/460 [==============================] - 0s 171us/step - loss: 0.4677 - accuracy: 0.7783\n",
      "Epoch 143/300\n",
      "460/460 [==============================] - 0s 176us/step - loss: 0.4899 - accuracy: 0.7761\n",
      "Epoch 144/300\n",
      "460/460 [==============================] - 0s 167us/step - loss: 0.4817 - accuracy: 0.7391\n",
      "Epoch 145/300\n",
      "460/460 [==============================] - 0s 167us/step - loss: 0.4864 - accuracy: 0.7543\n",
      "Epoch 146/300\n",
      "460/460 [==============================] - 0s 173us/step - loss: 0.4939 - accuracy: 0.7457\n",
      "Epoch 147/300\n",
      "460/460 [==============================] - 0s 171us/step - loss: 0.4762 - accuracy: 0.7457\n",
      "Epoch 148/300\n",
      "460/460 [==============================] - 0s 200us/step - loss: 0.4974 - accuracy: 0.7587\n",
      "Epoch 149/300\n",
      "460/460 [==============================] - 0s 319us/step - loss: 0.4797 - accuracy: 0.7804\n",
      "Epoch 150/300\n",
      "460/460 [==============================] - 0s 317us/step - loss: 0.5023 - accuracy: 0.7500\n",
      "Epoch 151/300\n",
      "460/460 [==============================] - 0s 304us/step - loss: 0.4791 - accuracy: 0.7652\n",
      "Epoch 152/300\n",
      "460/460 [==============================] - 0s 312us/step - loss: 0.4803 - accuracy: 0.7652\n",
      "Epoch 153/300\n",
      "460/460 [==============================] - 0s 308us/step - loss: 0.4758 - accuracy: 0.7674\n",
      "Epoch 154/300\n",
      "460/460 [==============================] - 0s 319us/step - loss: 0.5050 - accuracy: 0.7478\n",
      "Epoch 155/300\n",
      "460/460 [==============================] - 0s 308us/step - loss: 0.4694 - accuracy: 0.7870\n",
      "Epoch 156/300\n",
      "460/460 [==============================] - 0s 330us/step - loss: 0.4792 - accuracy: 0.7630\n",
      "Epoch 157/300\n",
      "460/460 [==============================] - 0s 403us/step - loss: 0.4326 - accuracy: 0.7978\n",
      "Epoch 158/300\n",
      "460/460 [==============================] - 0s 314us/step - loss: 0.4928 - accuracy: 0.7630\n",
      "Epoch 159/300\n",
      "460/460 [==============================] - 0s 310us/step - loss: 0.4481 - accuracy: 0.7804\n",
      "Epoch 160/300\n",
      "460/460 [==============================] - 0s 332us/step - loss: 0.4913 - accuracy: 0.7435\n",
      "Epoch 161/300\n",
      "460/460 [==============================] - 0s 312us/step - loss: 0.4906 - accuracy: 0.7565\n",
      "Epoch 162/300\n",
      "460/460 [==============================] - 0s 423us/step - loss: 0.4776 - accuracy: 0.7652\n",
      "Epoch 163/300\n",
      "460/460 [==============================] - 0s 319us/step - loss: 0.4582 - accuracy: 0.7696\n",
      "Epoch 164/300\n",
      "460/460 [==============================] - 0s 306us/step - loss: 0.4750 - accuracy: 0.7717\n",
      "Epoch 165/300\n",
      "460/460 [==============================] - 0s 310us/step - loss: 0.4738 - accuracy: 0.7739\n",
      "Epoch 166/300\n",
      "460/460 [==============================] - 0s 312us/step - loss: 0.4613 - accuracy: 0.7674\n",
      "Epoch 167/300\n",
      "460/460 [==============================] - 0s 323us/step - loss: 0.4746 - accuracy: 0.7978\n",
      "Epoch 168/300\n",
      "460/460 [==============================] - 0s 332us/step - loss: 0.4670 - accuracy: 0.7609\n",
      "Epoch 169/300\n",
      "460/460 [==============================] - 0s 304us/step - loss: 0.4607 - accuracy: 0.7717\n",
      "Epoch 170/300\n",
      "460/460 [==============================] - 0s 299us/step - loss: 0.4866 - accuracy: 0.7435\n",
      "Epoch 171/300\n",
      "460/460 [==============================] - 0s 321us/step - loss: 0.4953 - accuracy: 0.7587\n",
      "Epoch 172/300\n",
      "460/460 [==============================] - 0s 321us/step - loss: 0.4686 - accuracy: 0.7674\n",
      "Epoch 173/300\n",
      "460/460 [==============================] - 0s 332us/step - loss: 0.4870 - accuracy: 0.7457\n",
      "Epoch 174/300\n",
      "460/460 [==============================] - 0s 388us/step - loss: 0.4668 - accuracy: 0.7478\n",
      "Epoch 175/300\n",
      "460/460 [==============================] - 0s 392us/step - loss: 0.4847 - accuracy: 0.7630\n",
      "Epoch 176/300\n",
      "460/460 [==============================] - 0s 379us/step - loss: 0.4784 - accuracy: 0.75220s - loss: 0.4928 - accuracy: 0.\n",
      "Epoch 177/300\n",
      "460/460 [==============================] - 0s 401us/step - loss: 0.4742 - accuracy: 0.75650s - loss: 0.4790 - accuracy: 0.75\n",
      "Epoch 178/300\n",
      "460/460 [==============================] - 0s 392us/step - loss: 0.4744 - accuracy: 0.7630\n",
      "Epoch 179/300\n",
      "460/460 [==============================] - 0s 434us/step - loss: 0.4631 - accuracy: 0.7848\n",
      "Epoch 180/300\n",
      "460/460 [==============================] - 0s 382us/step - loss: 0.5010 - accuracy: 0.7457\n",
      "Epoch 181/300\n",
      "460/460 [==============================] - 0s 390us/step - loss: 0.4849 - accuracy: 0.7652\n",
      "Epoch 182/300\n",
      "460/460 [==============================] - 0s 390us/step - loss: 0.4521 - accuracy: 0.7717\n",
      "Epoch 183/300\n",
      "460/460 [==============================] - 0s 379us/step - loss: 0.4811 - accuracy: 0.7478\n",
      "Epoch 184/300\n",
      "460/460 [==============================] - 0s 397us/step - loss: 0.4746 - accuracy: 0.7696\n",
      "Epoch 185/300\n",
      "460/460 [==============================] - 0s 438us/step - loss: 0.4513 - accuracy: 0.7783\n",
      "Epoch 186/300\n",
      "460/460 [==============================] - 0s 434us/step - loss: 0.4706 - accuracy: 0.7717\n",
      "Epoch 187/300\n",
      "460/460 [==============================] - 0s 377us/step - loss: 0.4606 - accuracy: 0.7565\n",
      "Epoch 188/300\n",
      "460/460 [==============================] - 0s 312us/step - loss: 0.4310 - accuracy: 0.7891\n",
      "Epoch 189/300\n",
      "460/460 [==============================] - 0s 327us/step - loss: 0.4655 - accuracy: 0.7413\n",
      "Epoch 190/300\n",
      "460/460 [==============================] - 0s 364us/step - loss: 0.4643 - accuracy: 0.7413\n",
      "Epoch 191/300\n",
      "460/460 [==============================] - 0s 449us/step - loss: 0.4734 - accuracy: 0.7696\n",
      "Epoch 192/300\n",
      "460/460 [==============================] - 0s 336us/step - loss: 0.4709 - accuracy: 0.7739\n",
      "Epoch 193/300\n",
      "460/460 [==============================] - 0s 343us/step - loss: 0.4661 - accuracy: 0.7696\n",
      "Epoch 194/300\n",
      "460/460 [==============================] - 0s 327us/step - loss: 0.4555 - accuracy: 0.7674\n",
      "Epoch 195/300\n",
      "460/460 [==============================] - 0s 350us/step - loss: 0.4479 - accuracy: 0.7826\n",
      "Epoch 196/300\n",
      "460/460 [==============================] - 0s 340us/step - loss: 0.4686 - accuracy: 0.7717\n",
      "Epoch 197/300\n",
      "460/460 [==============================] - 0s 353us/step - loss: 0.4691 - accuracy: 0.7696\n",
      "Epoch 198/300\n",
      "  8/460 [..............................] - ETA: 0s - loss: 0.2175 - accuracy: 0.8750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-6bcff4ee0c2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m                            \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                            cv = 5)\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mbest_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mbest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    685\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    664\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 666\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_weight'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1434\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m         \u001b[1;31m# TODO(mrry): Switch to raising an exception from the SWIG wrapper.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1436\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mScopedTFStatus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\c_api_util.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_NewStatus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Tuning the Neural network\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "classifier = KerasClassifier(build_fn = build_classifier)\n",
    "parameters = {'batch_size': [8, 16, 32],\n",
    "              'epochs': [100, 300, 500]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 5)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7586805555555556, {'batch_size': 8, 'epochs': 100})"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy, best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
